4/15/2025
We finished up data cleaning and transformation today for our uses later in the project
This included fixing column names and creation of vector representations of the emotions/activites
present in each journal entry. We then did basic modeling using logistic regression and TD-if 
vectorization. 
The resulting accuracy is below
F1 Score (Macro): 0.12191325514387374
Precision (Micro): 0.7745901639344263
Recall (Micro): 0.21380090497737556
Exact Match Accuracy: 0.030508474576271188

4/24/2025
We worked on the fine-tuned DistilBERT model. Used Binary Cross-Entropy with Logits as the loss function.
Training Setup: 4 epochs, batch size 8, and learning rate 2e-5.
The resulting accuracy is below during epoch 4:
Training Loss: 0.1899
Eval Loss: 0.1832
F1 Micro: 0.5323
F1 Macro: 0.2736

Below is the classification report:
precision    recall  f1-score   support

      afraid       0.00      0.00      0.00         2
       angry       0.00      0.00      0.00         5
     anxious       0.50      0.04      0.08        23
     ashamed       0.00      0.00      0.00         4
     awkward       0.00      0.00      0.00         4
       bored       0.00      0.00      0.00        15
        calm       0.75      0.10      0.18        87
    confused       0.00      0.00      0.00         7
   disgusted       0.00      0.00      0.00         3
     excited       0.00      0.00      0.00        46
  frustrated       0.60      0.21      0.32        28
       happy       0.73      0.73      0.73       153
     jealous       0.00      0.00      0.00         0
   nostalgic       0.00      0.00      0.00         6
       proud       0.82      0.14      0.23        66
         sad       0.00      0.00      0.00         6
   satisfied       0.49      0.28      0.36       124
   surprised       0.00      0.00      0.00        10
    exercise       0.86      0.74      0.79        34
      family       0.90      0.68      0.77        53
        food       0.95      0.88      0.91        41
     friends       1.00      0.45      0.62        20
         god       1.00      0.42      0.59        19
      health       1.00      0.27      0.42        26
        love       0.00      0.00      0.00        10
  recreation       1.00      0.06      0.12        16
      school       0.00      0.00      0.00         1
       sleep       0.96      0.93      0.95        28
        work       0.90      0.81      0.85        47

   micro avg       0.78      0.40      0.53       884
   macro avg       0.43      0.23      0.27       884
weighted avg       0.66      0.40      0.46       884
 samples avg       0.69      0.42      0.50       884

This had strong performance for common classes like 'happy' but poor coverage for low frequency
emotions. To enhance the model, we added class weights, lowered the learning 
rate, had a learning rate scheduler, and increased epochs to 10 with early stopping. The best epoch
was 10 with the following result accuracy:
Training Loss: 0.3744
Eval Loss: 0.5491
F1 Micro: 0.5856
F1 Macro: 0.4784
F1 Weighted: 0.6143

Below is the classification report:
              precision    recall  f1-score   support

      afraid       0.09      1.00      0.16         2
       angry       0.12      0.60      0.20         5
     anxious       0.42      0.74      0.54        23
     ashamed       0.14      0.75      0.23         4
     awkward       0.07      0.25      0.11         4
       bored       0.32      0.53      0.40        15
        calm       0.54      0.49      0.52        87
    confused       0.19      0.57      0.29         7
   disgusted       0.04      0.33      0.08         3
     excited       0.33      0.17      0.23        46
  frustrated       0.46      0.68      0.55        28
       happy       0.74      0.69      0.71       153
     jealous       0.00      0.00      0.00         0
   nostalgic       0.16      0.50      0.24         6
       proud       0.47      0.47      0.47        66
         sad       0.14      0.67      0.24         6
   satisfied       0.48      0.59      0.53       124
   surprised       0.00      0.00      0.00        10
    exercise       0.73      0.97      0.84        34
      family       0.82      0.89      0.85        53
        food       0.95      0.90      0.93        41
     friends       0.76      0.65      0.70        20
         god       0.94      0.79      0.86        19
      health       0.67      0.62      0.64        26
        love       0.43      0.60      0.50        10
  recreation       0.71      0.62      0.67        16
      school       0.50      1.00      0.67         1
       sleep       0.79      0.96      0.87        28
        work       0.84      0.89      0.87        47

   micro avg       0.53      0.65      0.59       884
   macro avg       0.44      0.62      0.48       884
weighted avg       0.60      0.65      0.61       884
 samples avg       0.61      0.67      0.60       884

Per-Class Accuracy:
afraid: 0.9288
angry: 0.9186
anxious: 0.9017
ashamed: 0.9322
awkward: 0.9458
bored: 0.9186
calm: 0.7288
confused: 0.9322
disgusted: 0.9186
excited: 0.8169
frustrated: 0.8949
happy: 0.7119
jealous: 0.9831
nostalgic: 0.9356
proud: 0.7627
sad: 0.9119
satisfied: 0.5593
surprised: 0.9322
exercise: 0.9559
family: 0.9458
food: 0.9797
friends: 0.9627
god: 0.9831
health: 0.9390
love: 0.9593
recreation: 0.9661
school: 0.9966
sleep: 0.9729
work: 0.9559

The underrepresented classes saw boosts in recall and precision. 

//
Things we can try to improve the model:
- Use validation set to try diff thresholds per label instead of 0.5.
- Split data into train, val, test sets and use validation set to monitor F1, tune thresholds,
and select best model. 
- Since rare labels are underrepresented, use 'WeightedRandomSampler'??
- could try bert-base-uncased, roberta-base, or GoEmotions instead of DistilBERT
//

We analyzed how different topics co-occur with various emotions in journal entries.
We wrote code to build a co-occurence matrix that counts how often each emotions appears
alongside each topic. Then, it normalizes these coutns to show the distribution of topics 
within each emotion. We visualized using heatmaps.

//
We can do bar plots per emotion. We can also do logistic regression or Chi-square tests??
//
4/29/2024
These are results from the training using weighted random sampling
It doesn't seem to have helped at all. Loss even went up on the last epoch which wasn't seen in the previous model and the accuracy/
F1 scores both were lower. 
It seems to have helped wtih one or two labels that had very poor accuracy on the previous model like 
the emotion nostalgic but most others were pretty similar. 

Epoch 10/10
Training: 100%|██████████| 148/148 [31:03<00:00, 12.59s/it]
Training Loss: 0.4087
Evaluating: 100%|██████████| 37/37 [02:03<00:00,  3.33s/it]
Eval Loss: 0.5742
F1 Micro: 0.5342
F1 Macro: 0.4747
F1 Weighted: 0.5668

Best model was from epoch 9 with F1 micro of 0.5479

 Classification Report:

              precision    recall  f1-score   support

      afraid       0.14      0.50      0.22         2
       angry       0.18      0.40      0.25         5
     anxious       0.38      0.78      0.51        23
     ashamed       0.40      0.50      0.44         4
     awkward       0.09      0.25      0.13         4
       bored       0.30      0.53      0.38        15
        calm       0.53      0.36      0.43        87
    confused       0.25      0.29      0.27         7
   disgusted       0.00      0.00      0.00         3
     excited       0.22      0.48      0.31        46
  frustrated       0.50      0.64      0.56        28
       happy       0.74      0.69      0.71       153
     jealous       0.00      0.00      0.00         0
   nostalgic       0.05      0.83      0.10         6
       proud       0.49      0.53      0.51        66
         sad       0.17      0.67      0.27         6
   satisfied       0.49      0.68      0.57       124
   surprised       0.06      0.20      0.10        10
    exercise       0.82      0.94      0.88        34
      family       0.81      0.57      0.67        53
        food       0.94      0.83      0.88        41
     friends       0.64      0.80      0.71        20
         god       0.84      0.84      0.84        19
      health       0.59      0.62      0.60        26
        love       0.16      0.70      0.25        10
  recreation       0.50      0.62      0.56        16
      school       0.50      1.00      0.67         1
       sleep       0.81      0.93      0.87        28
        work       0.83      0.74      0.79        47

   micro avg       0.48      0.64      0.55       884
   macro avg       0.43      0.58      0.46       884
weighted avg       0.59      0.64      0.60       884
 samples avg       0.52      0.65      0.54       884


 Per-Class Accuracy:
afraid: 0.9763
angry: 0.9593
anxious: 0.8814
ashamed: 0.9831
awkward: 0.9559
bored: 0.9119
calm: 0.7186
confused: 0.9627
disgusted: 0.9729
excited: 0.6610
frustrated: 0.9051
happy: 0.7119
jealous: 0.9932
nostalgic: 0.7017
proud: 0.7729
sad: 0.9254
satisfied: 0.5695
surprised: 0.8746
exercise: 0.9695
family: 0.8983
food: 0.9695
friends: 0.9559
god: 0.9797
health: 0.9288
love: 0.8610
recreation: 0.9458
school: 0.9966
sleep: 0.9729
work: 0.9356


We changed it from a  single 80/20 train/test split with DistilBERT, using inverse‐frequency sample weights, a WeightedRandomSampler, 
per‐class pos_weight in the BCE loss, a ReduceLROnPlateau scheduler, up to ten epochs with early stopping, and a fixed 0.5 threshold
to a more robust five‐fold stratified cross‐validation ensemble built on the full bert-base-uncased model. We still use 20 percent of the data 
as a final test set, but we now train five separate BERT models—each on a different fold of the remaining 80 percent—and average 
their test‐time probabilities. Sequences are truncated to 128 tokens rather than 512, batch size is now 32, learning rate doubled to 
2 × 10⁻⁵, and epochs cut to three, with a linear warm‐up scheduler (10 percent of total steps) replacing the plateau scheduler. 
We also dispensed with explicit sample- or class-weighting in the data loader and loss function, instead relying on stratified 
folds to balance labels, and after ensembling, we perform a quick grid search over probabilities from 0.00 to 1.00 to find the 
optimal F₁-maximizing threshold for each label rather than using a one‐size‐fits‐all cutoff. Finally, rather than saving the 
best model per fold or early-stopping inside each fold, we aggregate all fold predictions, tune thresholds, and produce a single 
“ensembled” classification report.

Bert Model 1
Ensembled Classification Report:

              precision    recall  f1-score   support

      afraid       0.01      1.00      0.02         2
       angry       0.03      1.00      0.07         5
     anxious       0.09      0.96      0.16        23
     ashamed       0.02      1.00      0.03         4
     awkward       0.02      0.50      0.03         4
       bored       0.12      0.20      0.15        15
        calm       0.29      1.00      0.46        87
    confused       0.02      1.00      0.05         7
   disgusted       0.01      1.00      0.02         3
     excited       0.23      0.54      0.32        46
  frustrated       0.15      0.68      0.24        28
       happy       0.63      0.89      0.74       153
     jealous       0.00      0.00      0.00         0
   nostalgic       0.18      0.33      0.24         6
       proud       0.23      0.94      0.37        66
         sad       0.04      0.33      0.07         6
   satisfied       0.52      0.72      0.61       124
   surprised       0.03      1.00      0.07        10
...
   macro avg       0.21      0.63      0.24       884
weighted avg       0.38      0.72      0.45       884
 samples avg       0.17      0.70      0.27       884


Compared to the previous 3-epoch BERT ensemble, we changed it to make several targeted updates to improve regularization, 
metric-driven thresholding, and reproducibility. First, training is shortened to just two epochs per fold (down from three) 
and a 0.3 dropout layer is explicitly inserted before the classification head to combat overfitting. Second, the standard BCE 
loss has been replaced by a focal‐loss function (with α=1, γ=2) so that hard-to-classify examples receive more gradient focus. 
Third, instead of only collecting test-set probabilities, we now also capture each fold’s validation logits and labels so we can 
tune the per-label thresholds on out-of-fold data (using 5-percent increments) before applying them to the ensembled test logits. 
We also added an OUTPUT_DIR and CSV exports for the averaged test probabilities, final binary predictions, and the optimal thresholds, 
making downstream analysis and reproducibility much easier. All other core elements—128-token truncation, 32-example batches, 
a 5-fold stratified split, linear warm-up scheduler, and BERT-base multi-label head—remain the same.

Bert Model 2
Final Classification Report:

              precision    recall  f1-score   support

      afraid       0.01      1.00      0.02         2
       angry       0.03      0.40      0.06         5
     anxious       0.08      1.00      0.14        23
     ashamed       0.02      0.50      0.03         4
     awkward       0.01      1.00      0.03         4
       bored       0.11      0.20      0.14        15
        calm       0.29      1.00      0.46        87
    confused       0.00      0.00      0.00         7
   disgusted       0.01      1.00      0.02         3
     excited       0.16      1.00      0.27        46
  frustrated       0.09      1.00      0.17        28
       happy       0.52      1.00      0.68       153
     jealous       0.00      0.00      0.00         0
   nostalgic       0.02      1.00      0.04         6
       proud       0.22      1.00      0.37        66
         sad       0.00      0.00      0.00         6
   satisfied       0.42      1.00      0.59       124
   surprised       0.03      1.00      0.07        10
    exercise       0.12      1.00      0.21        34
      family       0.18      1.00      0.30        53
        food       0.14      1.00      0.24        41
     friends       0.07      1.00      0.13        20
         god       0.06      1.00      0.12        19
      health       0.09      1.00      0.16        26
        love       0.03      1.00      0.07        10
  recreation       0.00      0.00      0.00        16
      school       0.00      0.00      0.00         1
       sleep       0.19      0.86      0.31        28
        work       0.16      1.00      0.27        47

   micro avg       0.13      0.94      0.23       884
   macro avg       0.11      0.76      0.17       884
weighted avg       0.25      0.94      0.37       884
 samples avg       0.13      0.94      0.22       884


Next, we added a pre‐training cleanup step to drop any labels that appear in fewer than ten examples 
(to avoid spurious, “unstable” classes), and we've overhauled how we compute and apply class weights—now using the 
“effective number” formula to produce a normalized weight vector that gets passed into your focal‐loss function 
(which itself has been tweaked to α=0.25 and γ=3.0, and now accepts those per‐class weights). we still train a 5-fold 
BERT-base ensemble with two epochs and a 0.3 dropout layer, but our threshold‐search routine now first applies an asymmetric 
probability shift (×1.2 − 0.1, clipped to [0,1]) before scanning 5 % steps to maximize F₁, rather than working on raw probabilities.

Final Classification Report:

              precision    recall  f1-score   support

      afraid       0.00      0.00      0.00       2.0
       angry       0.00      0.00      0.00       5.0
     anxious       0.08      1.00      0.14      23.0
     ashamed       0.01      1.00      0.03       4.0
     awkward       0.04      0.25      0.07       4.0
       bored       0.05      1.00      0.10      15.0
        calm       0.29      1.00      0.46      87.0
    confused       0.00      0.00      0.00       7.0
   disgusted       0.00      0.00      0.00       3.0
     excited       0.16      1.00      0.27      46.0
  frustrated       0.09      1.00      0.17      28.0
       happy       0.52      1.00      0.68     153.0
   nostalgic       0.08      0.50      0.14       6.0
       proud       0.22      1.00      0.37      66.0
         sad       0.00      0.00      0.00       6.0
   satisfied       0.42      1.00      0.59     124.0
   surprised       0.03      1.00      0.07      10.0
    exercise       0.12      1.00      0.21      34.0
      family       0.18      1.00      0.30      53.0
        food       0.14      1.00      0.24      41.0
     friends       0.07      1.00      0.13      20.0
         god       0.06      1.00      0.12      19.0
      health       0.09      1.00      0.16      26.0
        love       0.03      1.00      0.07      10.0
  recreation       0.05      1.00      0.10      16.0
      school       0.00      1.00      0.01       1.0
       sleep       0.09      1.00      0.17      28.0
        work       0.16      1.00      0.27      47.0

   micro avg       0.14      0.97      0.24     884.0
   macro avg       0.11      0.78      0.17     884.0
weighted avg       0.25      0.97      0.37     884.0
 samples avg       0.14      0.97      0.24     884.0


 Roberta-base + other changes 
 Final Classification Report:
              precision    recall  f1-score   support

      afraid       0.00      0.00      0.00         2
       angry       0.10      0.40      0.16         5
     anxious       0.44      0.74      0.55        23
     ashamed       0.00      0.00      0.00         4
     awkward       0.00      0.00      0.00         4
       bored       0.15      0.13      0.14        15
        calm       0.29      1.00      0.46        87
    confused       0.33      0.43      0.38         7
   disgusted       0.00      0.00      0.00         3
     excited       0.16      1.00      0.27        46
  frustrated       0.49      0.79      0.60        28
       happy       0.52      1.00      0.68       153
   nostalgic       0.03      0.67      0.05         6
       proud       0.22      1.00      0.37        66
         sad       0.18      0.67      0.29         6
   satisfied       0.42      1.00      0.59       124
   surprised       0.00      0.00      0.00        10
    exercise       0.18      0.21      0.19        34
      family       0.30      0.91      0.45        53
        food       0.58      0.46      0.51        41
     friends       0.00      0.00      0.00        20
         god       0.35      0.42      0.38        19
      health       0.25      0.04      0.07        26
        love       0.06      0.20      0.10        10
  recreation       0.05      1.00      0.10        16
      school       0.00      0.00      0.00         1
       sleep       0.10      0.11      0.11        28
        work       0.16      1.00      0.27        47

   micro avg       0.25      0.77      0.38       884
   macro avg       0.19      0.47      0.24       884
weighted avg       0.32      0.77      0.42       884
 samples avg       0.27      0.75      0.38       884

Losing my mind so starting simple-
Epoch 1/5
67/67 ━━━━━━━━━━━━━━━━━━━━ 77s 1s/step - auc: 0.4856 - binary_accuracy: 0.5497 - loss: 0.7109 - val_auc: 0.4302 - val_binary_accuracy: 0.6502 - val_loss: 0.6275
Epoch 2/5
67/67 ━━━━━━━━━━━━━━━━━━━━ 75s 1s/step - auc: 0.4856 - binary_accuracy: 0.6981 - loss: 0.6177 - val_auc: 0.4674 - val_binary_accuracy: 0.8416 - val_loss: 0.5446
Epoch 3/5
67/67 ━━━━━━━━━━━━━━━━━━━━ 67s 994ms/step - auc: 0.4983 - binary_accuracy: 0.8080 - loss: 0.5355 - val_auc: 0.4827 - val_binary_accuracy: 0.8895 - val_loss: 0.4769
Epoch 4/5
67/67 ━━━━━━━━━━━━━━━━━━━━ 67s 1s/step - auc: 0.4893 - binary_accuracy: 0.8713 - loss: 0.4746 - val_auc: 0.4936 - val_binary_accuracy: 0.8895 - val_loss: 0.4235
Epoch 5/5
67/67 ━━━━━━━━━━━━━━━━━━━━ 67s 998ms/step - auc: 0.4935 - binary_accuracy: 0.8891 - loss: 0.4250 - val_auc: 0.5043 - val_binary_accuracy: 0.8895 - val_loss: 0.3814
10/10 ━━━━━━━━━━━━━━━━━━━━ 18s 2s/step

Adding class weighting for imbalancing, early stopping, cross validation, threshold optimization, and metrics

Can try to paper's approach next- 
BERT‑Base backbone + a two‑layer 768‑unit MLP with a sigmoid output head (29 labels).
BCE‑with‑logits loss for multi‑label training.
Five‑fold cross‑validation (80 / 20) and checkpoints for each fold.
normalised accuracy and macro‑F1 at a 0.20 threshold.