{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from data_cleaning_import import clean_create_vectors\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 148/148 [06:00<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:17<00:00,  2.16it/s]\n",
      "/opt/anaconda3/envs/bigdata2025/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.2788\n",
      "F1 Micro: 0.1510\n",
      "F1 Macro: 0.0205\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [05:55<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:17<00:00,  2.08it/s]\n",
      "/opt/anaconda3/envs/bigdata2025/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.2393\n",
      "F1 Micro: 0.2077\n",
      "F1 Macro: 0.0610\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [05:47<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:17<00:00,  2.12it/s]\n",
      "/opt/anaconda3/envs/bigdata2025/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.2036\n",
      "F1 Micro: 0.3959\n",
      "F1 Macro: 0.1578\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [06:15<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:17<00:00,  2.16it/s]\n",
      "/opt/anaconda3/envs/bigdata2025/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.1832\n",
      "F1 Micro: 0.5323\n",
      "F1 Macro: 0.2736\n",
      "✓ New best model saved!\n",
      "\n",
      "🔍 Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      afraid       0.00      0.00      0.00         2\n",
      "       angry       0.00      0.00      0.00         5\n",
      "     anxious       0.50      0.04      0.08        23\n",
      "     ashamed       0.00      0.00      0.00         4\n",
      "     awkward       0.00      0.00      0.00         4\n",
      "       bored       0.00      0.00      0.00        15\n",
      "        calm       0.75      0.10      0.18        87\n",
      "    confused       0.00      0.00      0.00         7\n",
      "   disgusted       0.00      0.00      0.00         3\n",
      "     excited       0.00      0.00      0.00        46\n",
      "  frustrated       0.60      0.21      0.32        28\n",
      "       happy       0.73      0.73      0.73       153\n",
      "     jealous       0.00      0.00      0.00         0\n",
      "   nostalgic       0.00      0.00      0.00         6\n",
      "       proud       0.82      0.14      0.23        66\n",
      "         sad       0.00      0.00      0.00         6\n",
      "   satisfied       0.49      0.28      0.36       124\n",
      "   surprised       0.00      0.00      0.00        10\n",
      "    exercise       0.86      0.74      0.79        34\n",
      "      family       0.90      0.68      0.77        53\n",
      "        food       0.95      0.88      0.91        41\n",
      "     friends       1.00      0.45      0.62        20\n",
      "         god       1.00      0.42      0.59        19\n",
      "      health       1.00      0.27      0.42        26\n",
      "        love       0.00      0.00      0.00        10\n",
      "  recreation       1.00      0.06      0.12        16\n",
      "      school       0.00      0.00      0.00         1\n",
      "       sleep       0.96      0.93      0.95        28\n",
      "        work       0.90      0.81      0.85        47\n",
      "\n",
      "   micro avg       0.78      0.40      0.53       884\n",
      "   macro avg       0.43      0.23      0.27       884\n",
      "weighted avg       0.66      0.40      0.46       884\n",
      " samples avg       0.69      0.42      0.50       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df = clean_create_vectors(df)\n",
    "\n",
    "X = df[\"journal\"].tolist()\n",
    "y = df.drop(columns=[\"journal\", \"emotion_vectors\", \"activity_vectors\"]).astype(int).values\n",
    "label_names = df.drop(columns=[\"journal\", \"emotion_vectors\", \"activity_vectors\"]).columns.tolist()\n",
    "num_labels = len(label_names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "class LemotifDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding='max_length', \n",
    "                                  max_length=max_length, return_tensors='pt')\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = LemotifDataset(X_train, y_train, tokenizer)\n",
    "test_dataset = LemotifDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "num_epochs = 4\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            loss = loss_fn(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = torch.sigmoid(logits) > 0.5\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / len(dataloader),\n",
    "        'f1_micro': f1_score(all_labels, all_preds, average='micro'),\n",
    "        'f1_macro': f1_score(all_labels, all_preds, average='macro')\n",
    "    }\n",
    "\n",
    "\n",
    "best_f1 = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, loss_fn, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    "\n",
    "    eval_results = evaluate(model, test_dataloader, loss_fn, device)\n",
    "    print(f\"Eval Loss: {eval_results['loss']:.4f}\")\n",
    "    print(f\"F1 Micro: {eval_results['f1_micro']:.4f}\")\n",
    "    print(f\"F1 Macro: {eval_results['f1_macro']:.4f}\")\n",
    "    \n",
    "\n",
    "    if eval_results['f1_micro'] > best_f1:\n",
    "        best_f1 = eval_results['f1_micro']\n",
    "        torch.save(model.state_dict(), \"./best_model.pt\")\n",
    "        print(\"✓ New best model saved!\")\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"./best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        preds = torch.sigmoid(logits) > 0.5\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(labels.numpy())\n",
    "\n",
    "all_preds = np.vstack(all_preds)\n",
    "all_labels = np.vstack(all_labels)\n",
    "\n",
    "print(\"\\n Classification Report:\\n\")\n",
    "print(classification_report(all_labels, all_preds, target_names=label_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[:1])\n",
    "\n",
    "class_counts = train_dataset.label.value_counts()\n",
    "print(train_dataset.label.value_counts())\n",
    "\n",
    "train_weights = 1 / class_counts\n",
    "\n",
    "sample_weights = [1/class_counts[i] for i in train_dataset.label.values]\n",
    "\n",
    "sampler = WeightedRandomSampler(weights = sample_weights, num_samples = len(train_dataset), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf9c020d2224e189ae50cafd51934a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([ 36.8125,  25.6087,   5.7745,  45.3077,  53.5455,  17.3235,   2.0961,\n",
      "         28.0476,  31.0000,   2.8732,   5.2124,   1.0208, 196.3333,  10.7091,\n",
      "          2.1734,  15.9189,   1.2612,  10.9074,   3.9007,   2.6532,   3.6358,\n",
      "          7.3625,  12.2708,   8.0685,  10.3333,   8.0685,  32.7222,   5.6635,\n",
      "          3.1330])\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [2:43:36<00:00, 66.33s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [02:29<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.9538\n",
      "F1 Micro: 0.0843\n",
      "F1 Macro: 0.0809\n",
      "F1 Weighted: 0.1283\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [37:35<00:00, 15.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [02:07<00:00,  3.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.8121\n",
      "F1 Micro: 0.2466\n",
      "F1 Macro: 0.1875\n",
      "F1 Weighted: 0.2702\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [46:10<00:00, 18.72s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [02:01<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.7414\n",
      "F1 Micro: 0.3168\n",
      "F1 Macro: 0.2474\n",
      "F1 Weighted: 0.3546\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [38:24<00:00, 15.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [02:09<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.6921\n",
      "F1 Micro: 0.3855\n",
      "F1 Macro: 0.3207\n",
      "F1 Weighted: 0.4306\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [2:03:06<00:00, 49.91s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [02:11<00:00,  3.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.6489\n",
      "F1 Micro: 0.4455\n",
      "F1 Macro: 0.3606\n",
      "F1 Weighted: 0.4906\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [36:14<00:00, 14.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [02:07<00:00,  3.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.6185\n",
      "F1 Micro: 0.4708\n",
      "F1 Macro: 0.3994\n",
      "F1 Weighted: 0.5299\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [39:14<00:00, 15.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [02:26<00:00,  3.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.5982\n",
      "F1 Micro: 0.4985\n",
      "F1 Macro: 0.4277\n",
      "F1 Weighted: 0.5512\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [31:08<00:00, 12.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [01:34<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.5798\n",
      "F1 Micro: 0.5031\n",
      "F1 Macro: 0.4306\n",
      "F1 Weighted: 0.5497\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [30:13<00:00, 12.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [01:40<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.5940\n",
      "F1 Micro: 0.5479\n",
      "F1 Macro: 0.4646\n",
      "F1 Weighted: 0.5965\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [31:03<00:00, 12.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [02:03<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.5742\n",
      "F1 Micro: 0.5342\n",
      "F1 Macro: 0.4747\n",
      "F1 Weighted: 0.5668\n",
      "\n",
      "Best model was from epoch 9 with F1 micro of 0.5479\n",
      "\n",
      " Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      afraid       0.14      0.50      0.22         2\n",
      "       angry       0.18      0.40      0.25         5\n",
      "     anxious       0.38      0.78      0.51        23\n",
      "     ashamed       0.40      0.50      0.44         4\n",
      "     awkward       0.09      0.25      0.13         4\n",
      "       bored       0.30      0.53      0.38        15\n",
      "        calm       0.53      0.36      0.43        87\n",
      "    confused       0.25      0.29      0.27         7\n",
      "   disgusted       0.00      0.00      0.00         3\n",
      "     excited       0.22      0.48      0.31        46\n",
      "  frustrated       0.50      0.64      0.56        28\n",
      "       happy       0.74      0.69      0.71       153\n",
      "     jealous       0.00      0.00      0.00         0\n",
      "   nostalgic       0.05      0.83      0.10         6\n",
      "       proud       0.49      0.53      0.51        66\n",
      "         sad       0.17      0.67      0.27         6\n",
      "   satisfied       0.49      0.68      0.57       124\n",
      "   surprised       0.06      0.20      0.10        10\n",
      "    exercise       0.82      0.94      0.88        34\n",
      "      family       0.81      0.57      0.67        53\n",
      "        food       0.94      0.83      0.88        41\n",
      "     friends       0.64      0.80      0.71        20\n",
      "         god       0.84      0.84      0.84        19\n",
      "      health       0.59      0.62      0.60        26\n",
      "        love       0.16      0.70      0.25        10\n",
      "  recreation       0.50      0.62      0.56        16\n",
      "      school       0.50      1.00      0.67         1\n",
      "       sleep       0.81      0.93      0.87        28\n",
      "        work       0.83      0.74      0.79        47\n",
      "\n",
      "   micro avg       0.48      0.64      0.55       884\n",
      "   macro avg       0.43      0.58      0.46       884\n",
      "weighted avg       0.59      0.64      0.60       884\n",
      " samples avg       0.52      0.65      0.54       884\n",
      "\n",
      "\n",
      " Per-Class Accuracy:\n",
      "afraid: 0.9763\n",
      "angry: 0.9593\n",
      "anxious: 0.8814\n",
      "ashamed: 0.9831\n",
      "awkward: 0.9559\n",
      "bored: 0.9119\n",
      "calm: 0.7186\n",
      "confused: 0.9627\n",
      "disgusted: 0.9729\n",
      "excited: 0.6610\n",
      "frustrated: 0.9051\n",
      "happy: 0.7119\n",
      "jealous: 0.9932\n",
      "nostalgic: 0.7017\n",
      "proud: 0.7729\n",
      "sad: 0.9254\n",
      "satisfied: 0.5695\n",
      "surprised: 0.8746\n",
      "exercise: 0.9695\n",
      "family: 0.8983\n",
      "food: 0.9695\n",
      "friends: 0.9559\n",
      "god: 0.9797\n",
      "health: 0.9288\n",
      "love: 0.8610\n",
      "recreation: 0.9458\n",
      "school: 0.9966\n",
      "sleep: 0.9729\n",
      "work: 0.9356\n",
      "\n",
      " Complete model saved to 'emotion_classification_model_complete.pt'\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df = clean_create_vectors(df)\n",
    "\n",
    "X = df[\"journal\"].tolist()\n",
    "y = df.drop(columns=[\"journal\", \"emotion_vectors\", \"activity_vectors\"]).astype(int).values\n",
    "label_names = df.drop(columns=[\"journal\", \"emotion_vectors\", \"activity_vectors\"]).columns.tolist()\n",
    "num_labels = len(label_names)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "label_counts = y_train.sum(axis=0)\n",
    "label_freqs = label_counts / y_train.shape[0]\n",
    "\n",
    "# Step 2: Inverse label frequency to assign higher weight to rare classes\n",
    "label_weights = 1.0 / (label_freqs + 1e-6)\n",
    "\n",
    "# Step 3: Compute sample weights\n",
    "sample_weights = (y_train * label_weights).sum(axis=1)\n",
    "\n",
    "# Normalize (optional)\n",
    "sample_weights = sample_weights / sample_weights.sum()\n",
    "\n",
    "# Step 4: Create WeightedRandomSampler\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "class LemotifDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding='max_length', \n",
    "                                  max_length=max_length, return_tensors='pt')\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = LemotifDataset(X_train, y_train, tokenizer)\n",
    "test_dataset = LemotifDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(train_dataset, sampler = sampler, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Calculate class weights to address class imbalance\n",
    "class_weights = []\n",
    "for i in range(num_labels):\n",
    "    \n",
    "    y_i = y_train[:, i]\n",
    "    if len(np.unique(y_i)) > 1:  \n",
    "        weights = compute_class_weight('balanced', classes=np.unique(y_i), y=y_i)\n",
    "        class_weights.append(weights[1] if len(weights) > 1 else 1.0)\n",
    "    else:\n",
    "        class_weights.append(1.0)\n",
    "\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# Changed training parameters \n",
    "learning_rate = 1e-5  # Lower learning rate \n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "num_epochs = 10  # Increased number of epochs\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)  # Using class weights in loss\n",
    "\n",
    "# Added learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1)\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            loss = loss_fn(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            \n",
    "            preds = torch.sigmoid(logits) > 0.5\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / len(dataloader),\n",
    "        'f1_micro': f1_score(all_labels, all_preds, average='micro'),\n",
    "        'f1_macro': f1_score(all_labels, all_preds, average='macro'),\n",
    "        'f1_weighted': f1_score(all_labels, all_preds, average='weighted'),\n",
    "        'preds': all_preds,\n",
    "        'labels': all_labels\n",
    "    }\n",
    "\n",
    "\n",
    "best_f1 = 0\n",
    "best_epoch = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "   \n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, loss_fn, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    " \n",
    "    eval_results = evaluate(model, test_dataloader, loss_fn, device)\n",
    "    print(f\"Eval Loss: {eval_results['loss']:.4f}\")\n",
    "    print(f\"F1 Micro: {eval_results['f1_micro']:.4f}\")\n",
    "    print(f\"F1 Macro: {eval_results['f1_macro']:.4f}\")\n",
    "    print(f\"F1 Weighted: {eval_results['f1_weighted']:.4f}\")\n",
    "    \n",
    "    \n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(eval_results['f1_micro'])\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if new_lr != old_lr:\n",
    "        print(f\"Learning rate changed from {old_lr} to {new_lr}\")\n",
    "    \n",
    "  \n",
    "    if eval_results['f1_micro'] > best_f1:\n",
    "        best_f1 = eval_results['f1_micro']\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), \"./best_model.pt\")\n",
    "        print(\"✓ New best model saved!\")\n",
    "    \n",
    "    # Early stopping \n",
    "    if epoch - best_epoch >= 3:  \n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest model was from epoch {best_epoch} with F1 micro of {best_f1:.4f}\")\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"./best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        preds = torch.sigmoid(logits) > 0.5\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(labels.numpy())\n",
    "\n",
    "all_preds = np.vstack(all_preds)\n",
    "all_labels = np.vstack(all_labels)\n",
    "\n",
    "print(\"\\n Classification Report:\\n\")\n",
    "print(classification_report(all_labels, all_preds, target_names=label_names, zero_division=0))\n",
    "\n",
    "\n",
    "class_correct = (all_preds == all_labels).sum(axis=0)\n",
    "class_total = all_labels.shape[0]\n",
    "class_accuracy = class_correct / class_total\n",
    "\n",
    "print(\"\\n Per-Class Accuracy:\")\n",
    "for i, label in enumerate(label_names):\n",
    "    print(f\"{label}: {class_accuracy[i]:.4f}\")\n",
    "\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'tokenizer': tokenizer,\n",
    "    'label_names': label_names,\n",
    "    'num_labels': num_labels\n",
    "}, \"emotion_classification_model_complete.pt\")\n",
    "print(\"\\n Complete model saved to 'emotion_classification_model_complete.pt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
