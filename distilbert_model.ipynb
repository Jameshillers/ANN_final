{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from data_cleaning_import import clean_create_vectors\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 148/148 [06:00<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:17<00:00,  2.16it/s]\n",
      "/opt/anaconda3/envs/bigdata2025/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.2788\n",
      "F1 Micro: 0.1510\n",
      "F1 Macro: 0.0205\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [05:55<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:17<00:00,  2.08it/s]\n",
      "/opt/anaconda3/envs/bigdata2025/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.2393\n",
      "F1 Micro: 0.2077\n",
      "F1 Macro: 0.0610\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [05:47<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:17<00:00,  2.12it/s]\n",
      "/opt/anaconda3/envs/bigdata2025/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.2036\n",
      "F1 Micro: 0.3959\n",
      "F1 Macro: 0.1578\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [06:15<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:17<00:00,  2.16it/s]\n",
      "/opt/anaconda3/envs/bigdata2025/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.1832\n",
      "F1 Micro: 0.5323\n",
      "F1 Macro: 0.2736\n",
      "✓ New best model saved!\n",
      "\n",
      "🔍 Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      afraid       0.00      0.00      0.00         2\n",
      "       angry       0.00      0.00      0.00         5\n",
      "     anxious       0.50      0.04      0.08        23\n",
      "     ashamed       0.00      0.00      0.00         4\n",
      "     awkward       0.00      0.00      0.00         4\n",
      "       bored       0.00      0.00      0.00        15\n",
      "        calm       0.75      0.10      0.18        87\n",
      "    confused       0.00      0.00      0.00         7\n",
      "   disgusted       0.00      0.00      0.00         3\n",
      "     excited       0.00      0.00      0.00        46\n",
      "  frustrated       0.60      0.21      0.32        28\n",
      "       happy       0.73      0.73      0.73       153\n",
      "     jealous       0.00      0.00      0.00         0\n",
      "   nostalgic       0.00      0.00      0.00         6\n",
      "       proud       0.82      0.14      0.23        66\n",
      "         sad       0.00      0.00      0.00         6\n",
      "   satisfied       0.49      0.28      0.36       124\n",
      "   surprised       0.00      0.00      0.00        10\n",
      "    exercise       0.86      0.74      0.79        34\n",
      "      family       0.90      0.68      0.77        53\n",
      "        food       0.95      0.88      0.91        41\n",
      "     friends       1.00      0.45      0.62        20\n",
      "         god       1.00      0.42      0.59        19\n",
      "      health       1.00      0.27      0.42        26\n",
      "        love       0.00      0.00      0.00        10\n",
      "  recreation       1.00      0.06      0.12        16\n",
      "      school       0.00      0.00      0.00         1\n",
      "       sleep       0.96      0.93      0.95        28\n",
      "        work       0.90      0.81      0.85        47\n",
      "\n",
      "   micro avg       0.78      0.40      0.53       884\n",
      "   macro avg       0.43      0.23      0.27       884\n",
      "weighted avg       0.66      0.40      0.46       884\n",
      " samples avg       0.69      0.42      0.50       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df = clean_create_vectors(df)\n",
    "\n",
    "X = df[\"journal\"].tolist()\n",
    "y = df.drop(columns=[\"journal\", \"emotion_vectors\", \"activity_vectors\"]).astype(int).values\n",
    "label_names = df.drop(columns=[\"journal\", \"emotion_vectors\", \"activity_vectors\"]).columns.tolist()\n",
    "num_labels = len(label_names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "class LemotifDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding='max_length', \n",
    "                                  max_length=max_length, return_tensors='pt')\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = LemotifDataset(X_train, y_train, tokenizer)\n",
    "test_dataset = LemotifDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "num_epochs = 4\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            loss = loss_fn(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = torch.sigmoid(logits) > 0.5\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / len(dataloader),\n",
    "        'f1_micro': f1_score(all_labels, all_preds, average='micro'),\n",
    "        'f1_macro': f1_score(all_labels, all_preds, average='macro')\n",
    "    }\n",
    "\n",
    "\n",
    "best_f1 = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, loss_fn, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    "\n",
    "    eval_results = evaluate(model, test_dataloader, loss_fn, device)\n",
    "    print(f\"Eval Loss: {eval_results['loss']:.4f}\")\n",
    "    print(f\"F1 Micro: {eval_results['f1_micro']:.4f}\")\n",
    "    print(f\"F1 Macro: {eval_results['f1_macro']:.4f}\")\n",
    "    \n",
    "\n",
    "    if eval_results['f1_micro'] > best_f1:\n",
    "        best_f1 = eval_results['f1_micro']\n",
    "        torch.save(model.state_dict(), \"./best_model.pt\")\n",
    "        print(\"✓ New best model saved!\")\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"./best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        preds = torch.sigmoid(logits) > 0.5\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(labels.numpy())\n",
    "\n",
    "all_preds = np.vstack(all_preds)\n",
    "all_labels = np.vstack(all_labels)\n",
    "\n",
    "print(\"\\n Classification Report:\\n\")\n",
    "print(classification_report(all_labels, all_preds, target_names=label_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([ 36.8125,  25.6087,   5.7745,  45.3077,  53.5455,  17.3235,   2.0961,\n",
      "         28.0476,  31.0000,   2.8732,   5.2124,   1.0208, 196.3333,  10.7091,\n",
      "          2.1734,  15.9189,   1.2612,  10.9074,   3.9007,   2.6532,   3.6358,\n",
      "          7.3625,  12.2708,   8.0685,  10.3333,   8.0685,  32.7222,   5.6635,\n",
      "          3.1330])\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [05:58<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:17<00:00,  2.13it/s]\n",
      "/opt/anaconda3/envs/bigdata2025/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/bigdata2025/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.8606\n",
      "F1 Micro: 0.2342\n",
      "F1 Macro: 0.0727\n",
      "F1 Weighted: 0.1628\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [06:01<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:17<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.7630\n",
      "F1 Micro: 0.3597\n",
      "F1 Macro: 0.2584\n",
      "F1 Weighted: 0.3444\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [05:55<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:17<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.6924\n",
      "F1 Micro: 0.4524\n",
      "F1 Macro: 0.3543\n",
      "F1 Weighted: 0.4482\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [05:51<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:17<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.6503\n",
      "F1 Micro: 0.4894\n",
      "F1 Macro: 0.3901\n",
      "F1 Weighted: 0.4958\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [05:45<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:16<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.6133\n",
      "F1 Micro: 0.5065\n",
      "F1 Macro: 0.4089\n",
      "F1 Weighted: 0.5452\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [05:37<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:16<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.5710\n",
      "F1 Micro: 0.5235\n",
      "F1 Macro: 0.4289\n",
      "F1 Weighted: 0.5667\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [05:48<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:17<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.5589\n",
      "F1 Micro: 0.5423\n",
      "F1 Macro: 0.4338\n",
      "F1 Weighted: 0.5782\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [05:50<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:18<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.5357\n",
      "F1 Micro: 0.5512\n",
      "F1 Macro: 0.4624\n",
      "F1 Weighted: 0.5802\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [05:56<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:17<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.5334\n",
      "F1 Micro: 0.5552\n",
      "F1 Macro: 0.4585\n",
      "F1 Weighted: 0.6006\n",
      "✓ New best model saved!\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 148/148 [06:00<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 37/37 [00:17<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.5491\n",
      "F1 Micro: 0.5856\n",
      "F1 Macro: 0.4784\n",
      "F1 Weighted: 0.6143\n",
      "✓ New best model saved!\n",
      "\n",
      "Best model was from epoch 10 with F1 micro of 0.5856\n",
      "\n",
      "🔍 Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      afraid       0.09      1.00      0.16         2\n",
      "       angry       0.12      0.60      0.20         5\n",
      "     anxious       0.42      0.74      0.54        23\n",
      "     ashamed       0.14      0.75      0.23         4\n",
      "     awkward       0.07      0.25      0.11         4\n",
      "       bored       0.32      0.53      0.40        15\n",
      "        calm       0.54      0.49      0.52        87\n",
      "    confused       0.19      0.57      0.29         7\n",
      "   disgusted       0.04      0.33      0.08         3\n",
      "     excited       0.33      0.17      0.23        46\n",
      "  frustrated       0.46      0.68      0.55        28\n",
      "       happy       0.74      0.69      0.71       153\n",
      "     jealous       0.00      0.00      0.00         0\n",
      "   nostalgic       0.16      0.50      0.24         6\n",
      "       proud       0.47      0.47      0.47        66\n",
      "         sad       0.14      0.67      0.24         6\n",
      "   satisfied       0.48      0.59      0.53       124\n",
      "   surprised       0.00      0.00      0.00        10\n",
      "    exercise       0.73      0.97      0.84        34\n",
      "      family       0.82      0.89      0.85        53\n",
      "        food       0.95      0.90      0.93        41\n",
      "     friends       0.76      0.65      0.70        20\n",
      "         god       0.94      0.79      0.86        19\n",
      "      health       0.67      0.62      0.64        26\n",
      "        love       0.43      0.60      0.50        10\n",
      "  recreation       0.71      0.62      0.67        16\n",
      "      school       0.50      1.00      0.67         1\n",
      "       sleep       0.79      0.96      0.87        28\n",
      "        work       0.84      0.89      0.87        47\n",
      "\n",
      "   micro avg       0.53      0.65      0.59       884\n",
      "   macro avg       0.44      0.62      0.48       884\n",
      "weighted avg       0.60      0.65      0.61       884\n",
      " samples avg       0.61      0.67      0.60       884\n",
      "\n",
      "\n",
      "📊 Per-Class Accuracy:\n",
      "afraid: 0.9288\n",
      "angry: 0.9186\n",
      "anxious: 0.9017\n",
      "ashamed: 0.9322\n",
      "awkward: 0.9458\n",
      "bored: 0.9186\n",
      "calm: 0.7288\n",
      "confused: 0.9322\n",
      "disgusted: 0.9186\n",
      "excited: 0.8169\n",
      "frustrated: 0.8949\n",
      "happy: 0.7119\n",
      "jealous: 0.9831\n",
      "nostalgic: 0.9356\n",
      "proud: 0.7627\n",
      "sad: 0.9119\n",
      "satisfied: 0.5593\n",
      "surprised: 0.9322\n",
      "exercise: 0.9559\n",
      "family: 0.9458\n",
      "food: 0.9797\n",
      "friends: 0.9627\n",
      "god: 0.9831\n",
      "health: 0.9390\n",
      "love: 0.9593\n",
      "recreation: 0.9661\n",
      "school: 0.9966\n",
      "sleep: 0.9729\n",
      "work: 0.9559\n",
      "\n",
      "✅ Complete model saved to 'emotion_classification_model_complete.pt'\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df = clean_create_vectors(df)\n",
    "\n",
    "X = df[\"journal\"].tolist()\n",
    "y = df.drop(columns=[\"journal\", \"emotion_vectors\", \"activity_vectors\"]).astype(int).values\n",
    "label_names = df.drop(columns=[\"journal\", \"emotion_vectors\", \"activity_vectors\"]).columns.tolist()\n",
    "num_labels = len(label_names)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "class LemotifDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding='max_length', \n",
    "                                  max_length=max_length, return_tensors='pt')\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = LemotifDataset(X_train, y_train, tokenizer)\n",
    "test_dataset = LemotifDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Calculate class weights to address class imbalance\n",
    "class_weights = []\n",
    "for i in range(num_labels):\n",
    "    \n",
    "    y_i = y_train[:, i]\n",
    "    if len(np.unique(y_i)) > 1:  \n",
    "        weights = compute_class_weight('balanced', classes=np.unique(y_i), y=y_i)\n",
    "        class_weights.append(weights[1] if len(weights) > 1 else 1.0)\n",
    "    else:\n",
    "        class_weights.append(1.0)\n",
    "\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# Changed training parameters \n",
    "learning_rate = 1e-5  # Lower learning rate \n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "num_epochs = 10  # Increased number of epochs\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)  # Using class weights in loss\n",
    "\n",
    "# Added learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1)\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            loss = loss_fn(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            \n",
    "            preds = torch.sigmoid(logits) > 0.5\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / len(dataloader),\n",
    "        'f1_micro': f1_score(all_labels, all_preds, average='micro'),\n",
    "        'f1_macro': f1_score(all_labels, all_preds, average='macro'),\n",
    "        'f1_weighted': f1_score(all_labels, all_preds, average='weighted'),\n",
    "        'preds': all_preds,\n",
    "        'labels': all_labels\n",
    "    }\n",
    "\n",
    "\n",
    "best_f1 = 0\n",
    "best_epoch = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "   \n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, loss_fn, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    " \n",
    "    eval_results = evaluate(model, test_dataloader, loss_fn, device)\n",
    "    print(f\"Eval Loss: {eval_results['loss']:.4f}\")\n",
    "    print(f\"F1 Micro: {eval_results['f1_micro']:.4f}\")\n",
    "    print(f\"F1 Macro: {eval_results['f1_macro']:.4f}\")\n",
    "    print(f\"F1 Weighted: {eval_results['f1_weighted']:.4f}\")\n",
    "    \n",
    "    \n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(eval_results['f1_micro'])\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if new_lr != old_lr:\n",
    "        print(f\"Learning rate changed from {old_lr} to {new_lr}\")\n",
    "    \n",
    "  \n",
    "    if eval_results['f1_micro'] > best_f1:\n",
    "        best_f1 = eval_results['f1_micro']\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), \"./best_model.pt\")\n",
    "        print(\"✓ New best model saved!\")\n",
    "    \n",
    "    # Early stopping \n",
    "    if epoch - best_epoch >= 3:  \n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest model was from epoch {best_epoch} with F1 micro of {best_f1:.4f}\")\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"./best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        preds = torch.sigmoid(logits) > 0.5\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(labels.numpy())\n",
    "\n",
    "all_preds = np.vstack(all_preds)\n",
    "all_labels = np.vstack(all_labels)\n",
    "\n",
    "print(\"\\n Classification Report:\\n\")\n",
    "print(classification_report(all_labels, all_preds, target_names=label_names, zero_division=0))\n",
    "\n",
    "\n",
    "class_correct = (all_preds == all_labels).sum(axis=0)\n",
    "class_total = all_labels.shape[0]\n",
    "class_accuracy = class_correct / class_total\n",
    "\n",
    "print(\"\\n Per-Class Accuracy:\")\n",
    "for i, label in enumerate(label_names):\n",
    "    print(f\"{label}: {class_accuracy[i]:.4f}\")\n",
    "\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'tokenizer': tokenizer,\n",
    "    'label_names': label_names,\n",
    "    'num_labels': num_labels\n",
    "}, \"emotion_classification_model_complete.pt\")\n",
    "print(\"\\n Complete model saved to 'emotion_classification_model_complete.pt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
