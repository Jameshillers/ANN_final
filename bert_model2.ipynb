{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW \n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fold1 Train E1: 100%|██████████| 29/29 [01:48<00:00,  3.74s/it]\n",
      "Fold1 Train E2: 100%|██████████| 29/29 [01:43<00:00,  3.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fold2 Train E1: 100%|██████████| 30/30 [01:47<00:00,  3.59s/it]\n",
      "Fold2 Train E2: 100%|██████████| 30/30 [01:51<00:00,  3.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fold3 Train E1: 100%|██████████| 30/30 [01:39<00:00,  3.33s/it]\n",
      "Fold3 Train E2: 100%|██████████| 30/30 [01:31<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fold4 Train E1: 100%|██████████| 30/30 [01:35<00:00,  3.19s/it]\n",
      "Fold4 Train E2: 100%|██████████| 30/30 [01:33<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fold5 Train E1: 100%|██████████| 30/30 [01:37<00:00,  3.24s/it]\n",
      "Fold5 Train E2: 100%|██████████| 30/30 [01:34<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: afraid | Best F1=0.032 @ threshold=0.3\n",
      "Label: angry | Best F1=0.042 @ threshold=0.35\n",
      "Label: anxious | Best F1=0.163 @ threshold=0.3\n",
      "Label: ashamed | Best F1=0.030 @ threshold=0.3\n",
      "Label: awkward | Best F1=0.022 @ threshold=0.3\n",
      "Label: bored | Best F1=0.059 @ threshold=0.3\n",
      "Label: calm | Best F1=0.388 @ threshold=0.35\n",
      "Label: confused | Best F1=0.052 @ threshold=0.35\n",
      "Label: disgusted | Best F1=0.032 @ threshold=0.05\n",
      "Label: excited | Best F1=0.296 @ threshold=0.05\n",
      "Label: frustrated | Best F1=0.175 @ threshold=0.05\n",
      "Label: happy | Best F1=0.658 @ threshold=0.45\n",
      "Label: jealous | Best F1=0.005 @ threshold=0.05\n",
      "Label: nostalgic | Best F1=0.096 @ threshold=0.3\n",
      "Label: proud | Best F1=0.375 @ threshold=0.35\n",
      "Label: sad | Best F1=0.065 @ threshold=0.35\n",
      "Label: satisfied | Best F1=0.569 @ threshold=0.4\n",
      "Label: surprised | Best F1=0.090 @ threshold=0.3\n",
      "Label: exercise | Best F1=0.229 @ threshold=0.35\n",
      "Label: family | Best F1=0.324 @ threshold=0.35\n",
      "Label: food | Best F1=0.267 @ threshold=0.35\n",
      "Label: friends | Best F1=0.131 @ threshold=0.3\n",
      "Label: god | Best F1=0.085 @ threshold=0.3\n",
      "Label: health | Best F1=0.128 @ threshold=0.3\n",
      "Label: love | Best F1=0.099 @ threshold=0.3\n",
      "Label: recreation | Best F1=0.119 @ threshold=0.35\n",
      "Label: school | Best F1=0.091 @ threshold=0.4\n",
      "Label: sleep | Best F1=0.175 @ threshold=0.35\n",
      "Label: work | Best F1=0.287 @ threshold=0.35\n",
      "\n",
      "Final Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      afraid       0.01      1.00      0.02         2\n",
      "       angry       0.03      0.40      0.06         5\n",
      "     anxious       0.08      1.00      0.14        23\n",
      "     ashamed       0.02      0.50      0.03         4\n",
      "     awkward       0.01      1.00      0.03         4\n",
      "       bored       0.11      0.20      0.14        15\n",
      "        calm       0.29      1.00      0.46        87\n",
      "    confused       0.00      0.00      0.00         7\n",
      "   disgusted       0.01      1.00      0.02         3\n",
      "     excited       0.16      1.00      0.27        46\n",
      "  frustrated       0.09      1.00      0.17        28\n",
      "       happy       0.52      1.00      0.68       153\n",
      "     jealous       0.00      0.00      0.00         0\n",
      "   nostalgic       0.02      1.00      0.04         6\n",
      "       proud       0.22      1.00      0.37        66\n",
      "         sad       0.00      0.00      0.00         6\n",
      "   satisfied       0.42      1.00      0.59       124\n",
      "   surprised       0.03      1.00      0.07        10\n",
      "    exercise       0.12      1.00      0.21        34\n",
      "      family       0.18      1.00      0.30        53\n",
      "        food       0.14      1.00      0.24        41\n",
      "     friends       0.07      1.00      0.13        20\n",
      "         god       0.06      1.00      0.12        19\n",
      "      health       0.09      1.00      0.16        26\n",
      "        love       0.03      1.00      0.07        10\n",
      "  recreation       0.00      0.00      0.00        16\n",
      "      school       0.00      0.00      0.00         1\n",
      "       sleep       0.19      0.86      0.31        28\n",
      "        work       0.16      1.00      0.27        47\n",
      "\n",
      "   micro avg       0.13      0.94      0.23       884\n",
      "   macro avg       0.11      0.76      0.17       884\n",
      "weighted avg       0.25      0.94      0.37       884\n",
      " samples avg       0.13      0.94      0.22       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "DATA_PATH = \"data.csv\"\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "LR = 2e-5\n",
    "NUM_EPOCHS = 2  # Reduced to 2-3 epochs\n",
    "WARMUP_RATIO = 0.1\n",
    "N_FOLDS = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "OUTPUT_DIR = \"model_output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Focal Loss definition\n",
    "def focal_loss_fn(logits, targets, alpha=1.0, gamma=2.0):\n",
    "    bce_loss = nn.functional.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "    p_t = torch.exp(-bce_loss)\n",
    "    focal_loss = alpha * (1 - p_t) ** gamma * bce_loss\n",
    "    return focal_loss.mean()\n",
    "\n",
    "# Dataset class\n",
    "class JournalDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.enc = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=MAX_SEQ_LEN,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.enc.input_ids[i],\n",
    "            \"attention_mask\": self.enc.attention_mask[i],\n",
    "            \"labels\": self.labels[i],\n",
    "        }\n",
    "\n",
    "# Threshold tuning (F1 objective)\n",
    "def find_optimal_thresholds(probs, true_labels, label_names):\n",
    "    thresholds = [v/100. for v in range(5, 100, 5)]\n",
    "    best_thresholds = {}\n",
    "    for i, label in enumerate(label_names):\n",
    "        best_score, best_thresh = 0, 0.5\n",
    "        for t in thresholds:\n",
    "            preds = (probs[:, i] >= t).astype(int)\n",
    "            f1 = f1_score(true_labels[:, i], preds, zero_division=0)\n",
    "            if f1 > best_score:\n",
    "                best_score, best_thresh = f1, t\n",
    "        best_thresholds[label] = best_thresh\n",
    "        print(f\"Label: {label} | Best F1={best_score:.3f} @ threshold={best_thresh}\")\n",
    "    return best_thresholds\n",
    "\n",
    "# Main training and ensembling\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    df = clean_create_vectors(df)\n",
    "    X = df[\"journal\"].tolist()\n",
    "    y_columns = [c for c in df.columns if c not in [\"journal\", \"emotion_vectors\", \"activity_vectors\"]]\n",
    "    y = df[y_columns].astype(int).values\n",
    "    label_names = y_columns\n",
    "    num_labels = len(label_names)\n",
    "\n",
    "    # Train-test split\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "    # Storage for logits and val probs\n",
    "    all_test_logits = np.zeros((len(X_test), num_labels))\n",
    "    all_val_probs = np.zeros((len(X_trainval), num_labels))\n",
    "    all_val_labels = np.zeros((len(X_trainval), num_labels))\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(mskf.split(X_trainval, y_trainval), 1):\n",
    "        print(f\"\\n=== Fold {fold}/{N_FOLDS} ===\")\n",
    "        # Prepare data\n",
    "        X_tr = [X_trainval[i] for i in tr_idx]; y_tr = y_trainval[tr_idx]\n",
    "        X_val = [X_trainval[i] for i in val_idx]; y_val = y_trainval[val_idx]\n",
    "\n",
    "        tr_ds = JournalDataset(X_tr, y_tr, tokenizer)\n",
    "        val_ds = JournalDataset(X_val, y_val, tokenizer)\n",
    "        test_ds = JournalDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "        tr_dl = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "        test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "        # Model\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            MODEL_NAME,\n",
    "            num_labels=num_labels,\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        ).to(DEVICE)\n",
    "        model.dropout = nn.Dropout(0.3)  # add dropout before classifier\n",
    "\n",
    "        optimizer = AdamW(model.parameters(), lr=LR)\n",
    "        total_steps = len(tr_dl) * NUM_EPOCHS\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=int(total_steps * WARMUP_RATIO),\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(1, NUM_EPOCHS+1):\n",
    "            model.train()\n",
    "            for batch in tqdm(tr_dl, desc=f\"Fold{fold} Train E{epoch}\"):\n",
    "                optimizer.zero_grad()\n",
    "                inputs = {k: v.to(DEVICE) for k, v in batch.items() if k != \"labels\"}\n",
    "                labels = batch[\"labels\"].to(DEVICE)\n",
    "                logits = model(**inputs).logits\n",
    "                loss = focal_loss_fn(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "        # Validation probabilities\n",
    "        model.eval()\n",
    "        val_logits, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dl:\n",
    "                inputs = {k: v.to(DEVICE) for k, v in batch.items() if k != \"labels\"}\n",
    "                logits = model(**inputs).logits.cpu().numpy()\n",
    "                val_logits.append(logits)\n",
    "                val_labels.append(batch[\"labels\"].numpy())\n",
    "        val_logits = np.vstack(val_logits)\n",
    "        val_probs = torch.sigmoid(torch.tensor(val_logits)).numpy()\n",
    "        all_val_probs[val_idx] = val_probs\n",
    "        all_val_labels[val_idx] = y_val\n",
    "\n",
    "        # Test logits\n",
    "        fold_test_logits = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_dl:\n",
    "                inputs = {k: v.to(DEVICE) for k, v in batch.items() if k != \"labels\"}\n",
    "                logits = model(**inputs).logits.cpu().numpy()\n",
    "                fold_test_logits.append(logits)\n",
    "        all_test_logits += np.vstack(fold_test_logits)\n",
    "\n",
    "    # Average logits and probs\n",
    "    avg_test_logits = all_test_logits / N_FOLDS\n",
    "    avg_test_probs = torch.sigmoid(torch.tensor(avg_test_logits)).numpy()\n",
    "\n",
    "    # Threshold tuning using F1 objective\n",
    "    best_thresholds = find_optimal_thresholds(all_val_probs, all_val_labels, label_names)\n",
    "\n",
    "    # Final predictions\n",
    "    final_preds = np.zeros_like(avg_test_probs, dtype=int)\n",
    "    for i, label in enumerate(label_names):\n",
    "        t = best_thresholds[label]\n",
    "        final_preds[:, i] = (avg_test_probs[:, i] >= t).astype(int)\n",
    "\n",
    "    # Report results\n",
    "    print(\"\\nFinal Classification Report:\\n\")\n",
    "    print(classification_report(y_test, final_preds, target_names=label_names, zero_division=0))\n",
    "\n",
    "    # Save outputs\n",
    "    pd.DataFrame(avg_test_probs, columns=label_names).to_csv(\n",
    "        os.path.join(OUTPUT_DIR, 'test_probabilities.csv'), index=False\n",
    "    )\n",
    "    pd.DataFrame(final_preds, columns=label_names).to_csv(\n",
    "        os.path.join(OUTPUT_DIR, 'test_predictions.csv'), index=False\n",
    "    )\n",
    "    pd.DataFrame.from_dict(best_thresholds, orient='index', columns=['threshold']).to_csv(\n",
    "        os.path.join(OUTPUT_DIR, 'optimal_thresholds.csv')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing unstable labels with <10 samples: ['jealous']\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fold1 Train E1: 100%|██████████| 30/30 [01:39<00:00,  3.33s/it]\n",
      "Fold1 Train E2: 100%|██████████| 30/30 [01:38<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fold2 Train E1: 100%|██████████| 30/30 [01:37<00:00,  3.26s/it]\n",
      "Fold2 Train E2: 100%|██████████| 30/30 [01:37<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fold3 Train E1: 100%|██████████| 30/30 [01:38<00:00,  3.27s/it]\n",
      "Fold3 Train E2: 100%|██████████| 30/30 [01:43<00:00,  3.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fold4 Train E1: 100%|██████████| 30/30 [01:39<00:00,  3.31s/it]\n",
      "Fold4 Train E2: 100%|██████████| 30/30 [01:39<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fold5 Train E1: 100%|██████████| 30/30 [01:43<00:00,  3.46s/it]\n",
      "Fold5 Train E2: 100%|██████████| 30/30 [01:49<00:00,  3.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: afraid | Best F1=0.049 @ threshold=0.6\n",
      "Label: angry | Best F1=0.042 @ threshold=0.65\n",
      "Label: anxious | Best F1=0.160 @ threshold=0.35\n",
      "Label: ashamed | Best F1=0.023 @ threshold=0.45\n",
      "Label: awkward | Best F1=0.024 @ threshold=0.5\n",
      "Label: bored | Best F1=0.059 @ threshold=0.45\n",
      "Label: calm | Best F1=0.385 @ threshold=0.05\n",
      "Label: confused | Best F1=0.043 @ threshold=0.65\n",
      "Label: disgusted | Best F1=0.047 @ threshold=0.55\n",
      "Label: excited | Best F1=0.296 @ threshold=0.05\n",
      "Label: frustrated | Best F1=0.176 @ threshold=0.35\n",
      "Label: happy | Best F1=0.659 @ threshold=0.45\n",
      "Label: nostalgic | Best F1=0.090 @ threshold=0.5\n",
      "Label: proud | Best F1=0.374 @ threshold=0.05\n",
      "Label: sad | Best F1=0.065 @ threshold=0.6\n",
      "Label: satisfied | Best F1=0.569 @ threshold=0.4\n",
      "Label: surprised | Best F1=0.093 @ threshold=0.45\n",
      "Label: exercise | Best F1=0.229 @ threshold=0.45\n",
      "Label: family | Best F1=0.323 @ threshold=0.4\n",
      "Label: food | Best F1=0.242 @ threshold=0.4\n",
      "Label: friends | Best F1=0.128 @ threshold=0.4\n",
      "Label: god | Best F1=0.079 @ threshold=0.4\n",
      "Label: health | Best F1=0.117 @ threshold=0.05\n",
      "Label: love | Best F1=0.092 @ threshold=0.05\n",
      "Label: recreation | Best F1=0.120 @ threshold=0.5\n",
      "Label: school | Best F1=0.030 @ threshold=0.3\n",
      "Label: sleep | Best F1=0.165 @ threshold=0.35\n",
      "Label: work | Best F1=0.279 @ threshold=0.35\n",
      "\n",
      "Final Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      afraid       0.00      0.00      0.00       2.0\n",
      "       angry       0.00      0.00      0.00       5.0\n",
      "     anxious       0.08      1.00      0.14      23.0\n",
      "     ashamed       0.01      1.00      0.03       4.0\n",
      "     awkward       0.04      0.25      0.07       4.0\n",
      "       bored       0.05      1.00      0.10      15.0\n",
      "        calm       0.29      1.00      0.46      87.0\n",
      "    confused       0.00      0.00      0.00       7.0\n",
      "   disgusted       0.00      0.00      0.00       3.0\n",
      "     excited       0.16      1.00      0.27      46.0\n",
      "  frustrated       0.09      1.00      0.17      28.0\n",
      "       happy       0.52      1.00      0.68     153.0\n",
      "   nostalgic       0.08      0.50      0.14       6.0\n",
      "       proud       0.22      1.00      0.37      66.0\n",
      "         sad       0.00      0.00      0.00       6.0\n",
      "   satisfied       0.42      1.00      0.59     124.0\n",
      "   surprised       0.03      1.00      0.07      10.0\n",
      "    exercise       0.12      1.00      0.21      34.0\n",
      "      family       0.18      1.00      0.30      53.0\n",
      "        food       0.14      1.00      0.24      41.0\n",
      "     friends       0.07      1.00      0.13      20.0\n",
      "         god       0.06      1.00      0.12      19.0\n",
      "      health       0.09      1.00      0.16      26.0\n",
      "        love       0.03      1.00      0.07      10.0\n",
      "  recreation       0.05      1.00      0.10      16.0\n",
      "      school       0.00      1.00      0.01       1.0\n",
      "       sleep       0.09      1.00      0.17      28.0\n",
      "        work       0.16      1.00      0.27      47.0\n",
      "\n",
      "   micro avg       0.14      0.97      0.24     884.0\n",
      "   macro avg       0.11      0.78      0.17     884.0\n",
      "weighted avg       0.25      0.97      0.37     884.0\n",
      " samples avg       0.14      0.97      0.24     884.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"data.csv\"\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "LR = 2e-5\n",
    "NUM_EPOCHS = 2  # Reduced to 2-3 epochs\n",
    "WARMUP_RATIO = 0.1\n",
    "N_FOLDS = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "OUTPUT_DIR = \"model_output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = clean_create_vectors(df)\n",
    "# Identify label columns\n",
    "y_columns = [c for c in df.columns if c not in [\"journal\", \"emotion_vectors\", \"activity_vectors\"]]\n",
    "\n",
    "# Address Data Sparsity: remove labels with <10 samples\n",
    "label_counts = df[y_columns].sum()\n",
    "unstable_labels = label_counts[label_counts < 10].index.tolist()\n",
    "if unstable_labels:\n",
    "    print(f\"Removing unstable labels with <10 samples: {unstable_labels}\")\n",
    "y_columns = [c for c in y_columns if c not in unstable_labels]\n",
    "\n",
    "# Final labels and texts\n",
    "label_names = y_columns\n",
    "num_labels = len(label_names)\n",
    "X = df[\"journal\"].tolist()\n",
    "y = df[label_names].astype(int).values\n",
    "\n",
    "# Fix Class Weight Calculation\n",
    "class_counts = np.sum(y, axis=0)\n",
    "effective_num = 1.0 / (class_counts + 1e-9)\n",
    "weights = (1.0 / effective_num) / np.sum(1.0 / effective_num)\n",
    "class_weights = torch.tensor(weights, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "# Focal Loss definition with class weights\n",
    "def focal_loss_fn(logits, targets, alpha=0.25, gamma=3.0, weights=None):\n",
    "    bce_loss = nn.functional.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "    if weights is not None:\n",
    "        bce_loss = bce_loss * weights\n",
    "    p_t = torch.exp(-bce_loss)\n",
    "    focal_loss = alpha * (1 - p_t) ** gamma * bce_loss\n",
    "    return focal_loss.mean()\n",
    "\n",
    "# Dataset class\n",
    "class JournalDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.enc = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=MAX_SEQ_LEN,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.enc.input_ids[i],\n",
    "            \"attention_mask\": self.enc.attention_mask[i],\n",
    "            \"labels\": self.labels[i],\n",
    "        }\n",
    "\n",
    "# Threshold tuning with Asymmetric Probability Shift\n",
    "def find_optimal_thresholds(probs, true_labels, label_names):\n",
    "    # Apply asymmetric probability shift\n",
    "    shifted_probs = probs.copy()\n",
    "    for i in range(shifted_probs.shape[1]):\n",
    "        shifted_probs[:, i] = np.clip(shifted_probs[:, i] * 1.2 - 0.1, 0, 1)\n",
    "\n",
    "    thresholds = [v/100. for v in range(5, 100, 5)]\n",
    "    best_thresholds = {}\n",
    "    for i, label in enumerate(label_names):\n",
    "        best_score, best_thresh = 0, 0.5\n",
    "        for t in thresholds:\n",
    "            preds = (shifted_probs[:, i] >= t).astype(int)\n",
    "            f1 = f1_score(true_labels[:, i], preds, zero_division=0)\n",
    "            if f1 > best_score:\n",
    "                best_score, best_thresh = f1, t\n",
    "        best_thresholds[label] = best_thresh\n",
    "        print(f\"Label: {label} | Best F1={best_score:.3f} @ threshold={best_thresh}\")\n",
    "    return best_thresholds\n",
    "\n",
    "# Main training and ensembling\n",
    "if __name__ == \"__main__\":\n",
    "    # Train-test split\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "    # Storage for logits and val probs\n",
    "    all_test_logits = np.zeros((len(X_test), num_labels))\n",
    "    all_val_probs = np.zeros((len(X_trainval), num_labels))\n",
    "    all_val_labels = np.zeros((len(X_trainval), num_labels))\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(mskf.split(X_trainval, y_trainval), 1):\n",
    "        print(f\"\\n=== Fold {fold}/{N_FOLDS} ===\")\n",
    "        # Prepare data\n",
    "        X_tr = [X_trainval[i] for i in tr_idx]; y_tr = y_trainval[tr_idx]\n",
    "        X_val = [X_trainval[i] for i in val_idx]; y_val = y_trainval[val_idx]\n",
    "\n",
    "        tr_ds = JournalDataset(X_tr, y_tr, tokenizer)\n",
    "        val_ds = JournalDataset(X_val, y_val, tokenizer)\n",
    "        test_ds = JournalDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "        tr_dl = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "        test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "        # Model\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            MODEL_NAME,\n",
    "            num_labels=num_labels,\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        ).to(DEVICE)\n",
    "        model.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        optimizer = AdamW(model.parameters(), lr=LR)\n",
    "        total_steps = len(tr_dl) * NUM_EPOCHS\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=int(total_steps * WARMUP_RATIO),\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(1, NUM_EPOCHS+1):\n",
    "            model.train()\n",
    "            for batch in tqdm(tr_dl, desc=f\"Fold{fold} Train E{epoch}\"):\n",
    "                optimizer.zero_grad()\n",
    "                inputs = {k: v.to(DEVICE) for k, v in batch.items() if k != \"labels\"}\n",
    "                labels = batch[\"labels\"].to(DEVICE)\n",
    "                logits = model(**inputs).logits\n",
    "                loss = focal_loss_fn(logits, labels, weights=class_weights)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "        # Validation probabilities\n",
    "        model.eval()\n",
    "        val_logits, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dl:\n",
    "                inputs = {k: v.to(DEVICE) for k, v in batch.items() if k != \"labels\"}\n",
    "                logits = model(**inputs).logits.cpu().numpy()\n",
    "                val_logits.append(logits)\n",
    "                val_labels.append(batch[\"labels\"].numpy())\n",
    "        val_logits = np.vstack(val_logits)\n",
    "        val_probs = torch.sigmoid(torch.tensor(val_logits)).numpy()\n",
    "        all_val_probs[val_idx] = val_probs\n",
    "        all_val_labels[val_idx] = y_val\n",
    "\n",
    "        # Test logits\n",
    "        fold_test_logits = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_dl:\n",
    "                inputs = {k: v.to(DEVICE) for k, v in batch.items() if k != \"labels\"}\n",
    "                logits = model(**inputs).logits.cpu().numpy()\n",
    "                fold_test_logits.append(logits)\n",
    "        all_test_logits += np.vstack(fold_test_logits)\n",
    "\n",
    "    # Average logits and probs\n",
    "    avg_test_logits = all_test_logits / N_FOLDS\n",
    "    avg_test_probs = torch.sigmoid(torch.tensor(avg_test_logits)).numpy()\n",
    "\n",
    "    # Threshold tuning using F1 objective\n",
    "    best_thresholds = find_optimal_thresholds(all_val_probs, all_val_labels, label_names)\n",
    "\n",
    "    # Final predictions\n",
    "    final_preds = np.zeros_like(avg_test_probs, dtype=int)\n",
    "    for i, label in enumerate(label_names):\n",
    "        t = best_thresholds[label]\n",
    "        final_preds[:, i] = (avg_test_probs[:, i] >= t).astype(int)\n",
    "\n",
    "    # Report results with sample-wise filtering\n",
    "    print(\"\\nFinal Classification Report:\\n\")\n",
    "    print(classification_report(\n",
    "        y_test, final_preds,\n",
    "        target_names=label_names,\n",
    "        zero_division=0,\n",
    "        sample_weight=(y_test.sum(axis=1) > 0)\n",
    "    ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score, precision_recall_curve\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModel,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoModelForSequenceClassification\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# Import seaborn only if visualization is needed\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except ImportError:\n",
    "    print(\"Seaborn not installed. Visualizations will be limited.\")\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from data_cleaning_import import clean_create_vectors\n",
    "from torch.optim import AdamW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing unstable labels with <5 samples: ['jealous']\n",
      "Class distribution: {'afraid': np.int64(18), 'angry': np.int64(28), 'anxious': np.int64(125), 'ashamed': np.int64(17), 'awkward': np.int64(15), 'bored': np.int64(49), 'calm': np.int64(368), 'confused': np.int64(28), 'disgusted': np.int64(22), 'excited': np.int64(251), 'frustrated': np.int64(141), 'happy': np.int64(730), 'nostalgic': np.int64(61), 'proud': np.int64(337), 'sad': np.int64(43), 'satisfied': np.int64(591), 'surprised': np.int64(64), 'exercise': np.int64(185), 'family': np.int64(275), 'food': np.int64(203), 'friends': np.int64(100), 'god': np.int64(67), 'health': np.int64(99), 'love': np.int64(67), 'recreation': np.int64(89), 'school': np.int64(19), 'sleep': np.int64(132), 'work': np.int64(235)}\n",
      "Training samples: 1178, Test samples: 295\n",
      "Label distribution in train/test:\n",
      "  afraid: 16 train, 2 test\n",
      "  angry: 23 train, 5 test\n",
      "  anxious: 102 train, 23 test\n",
      "  ashamed: 13 train, 4 test\n",
      "  awkward: 11 train, 4 test\n",
      "  bored: 34 train, 15 test\n",
      "  calm: 281 train, 87 test\n",
      "  confused: 21 train, 7 test\n",
      "  disgusted: 19 train, 3 test\n",
      "  excited: 205 train, 46 test\n",
      "  frustrated: 113 train, 28 test\n",
      "  happy: 577 train, 153 test\n",
      "  nostalgic: 55 train, 6 test\n",
      "  proud: 271 train, 66 test\n",
      "  sad: 37 train, 6 test\n",
      "  satisfied: 467 train, 124 test\n",
      "  surprised: 54 train, 10 test\n",
      "  exercise: 151 train, 34 test\n",
      "  family: 222 train, 53 test\n",
      "  food: 162 train, 41 test\n",
      "  friends: 80 train, 20 test\n",
      "  god: 48 train, 19 test\n",
      "  health: 73 train, 26 test\n",
      "  love: 57 train, 10 test\n",
      "  recreation: 73 train, 16 test\n",
      "  school: 18 train, 1 test\n",
      "  sleep: 104 train, 28 test\n",
      "  work: 188 train, 47 test\n",
      "\n",
      "=== Fold 1/5 (stratified) ===\n",
      "Augmenting minority classes for this fold...\n",
      "Original dataset size: 941, Augmented size: 983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b52f532573241578fc2170d2b0828b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Train E1: 100%|██████████| 62/62 [03:52<00:00,  3.75s/it]\n",
      "Val E1: 100%|██████████| 15/15 [00:12<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.1022, Val Loss = 0.0425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E2: 100%|██████████| 62/62 [03:49<00:00,  3.70s/it]\n",
      "Val E2: 100%|██████████| 15/15 [00:12<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.0479, Val Loss = 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E3: 100%|██████████| 62/62 [03:36<00:00,  3.50s/it]\n",
      "Val E3: 100%|██████████| 15/15 [00:12<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.0451, Val Loss = 0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E4: 100%|██████████| 62/62 [03:34<00:00,  3.46s/it]\n",
      "Val E4: 100%|██████████| 15/15 [00:12<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.0427, Val Loss = 0.0348\n",
      "\n",
      "=== Fold 2/5 (stratified) ===\n",
      "Augmenting minority classes for this fold...\n",
      "Original dataset size: 942, Augmented size: 984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Train E1: 100%|██████████| 62/62 [03:34<00:00,  3.46s/it]\n",
      "Val E1: 100%|██████████| 15/15 [00:12<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.1033, Val Loss = 0.0436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E2: 100%|██████████| 62/62 [03:39<00:00,  3.53s/it]\n",
      "Val E2: 100%|██████████| 15/15 [00:12<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.0491, Val Loss = 0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E3: 100%|██████████| 62/62 [03:39<00:00,  3.54s/it]\n",
      "Val E3: 100%|██████████| 15/15 [00:12<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.0453, Val Loss = 0.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E4: 100%|██████████| 62/62 [03:37<00:00,  3.50s/it]\n",
      "Val E4: 100%|██████████| 15/15 [00:12<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.0429, Val Loss = 0.0357\n",
      "\n",
      "=== Fold 3/5 (stratified) ===\n",
      "Augmenting minority classes for this fold...\n",
      "Original dataset size: 943, Augmented size: 987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Train E1: 100%|██████████| 62/62 [03:37<00:00,  3.51s/it]\n",
      "Val E1: 100%|██████████| 15/15 [00:12<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.1087, Val Loss = 0.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E2: 100%|██████████| 62/62 [03:38<00:00,  3.52s/it]\n",
      "Val E2: 100%|██████████| 15/15 [00:12<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.0526, Val Loss = 0.0401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E3: 100%|██████████| 62/62 [03:38<00:00,  3.53s/it]\n",
      "Val E3: 100%|██████████| 15/15 [00:12<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.0481, Val Loss = 0.0387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E4: 100%|██████████| 62/62 [03:37<00:00,  3.51s/it]\n",
      "Val E4: 100%|██████████| 15/15 [00:11<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.0461, Val Loss = 0.0379\n",
      "\n",
      "=== Fold 4/5 (stratified) ===\n",
      "Augmenting minority classes for this fold...\n",
      "Original dataset size: 944, Augmented size: 987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Train E1: 100%|██████████| 62/62 [03:41<00:00,  3.57s/it]\n",
      "Val E1: 100%|██████████| 15/15 [00:12<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.1059, Val Loss = 0.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E2: 100%|██████████| 62/62 [03:39<00:00,  3.53s/it]\n",
      "Val E2: 100%|██████████| 15/15 [00:11<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.0504, Val Loss = 0.0389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E3: 100%|██████████| 62/62 [03:42<00:00,  3.59s/it]\n",
      "Val E3: 100%|██████████| 15/15 [00:12<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.0456, Val Loss = 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E4: 100%|██████████| 62/62 [03:42<00:00,  3.58s/it]\n",
      "Val E4: 100%|██████████| 15/15 [00:12<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.0426, Val Loss = 0.0363\n",
      "\n",
      "=== Fold 5/5 (stratified) ===\n",
      "Augmenting minority classes for this fold...\n",
      "Original dataset size: 942, Augmented size: 987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Train E1: 100%|██████████| 62/62 [03:43<00:00,  3.60s/it]\n",
      "Val E1: 100%|██████████| 15/15 [00:12<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.1055, Val Loss = 0.0479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E2: 100%|██████████| 62/62 [03:44<00:00,  3.61s/it]\n",
      "Val E2: 100%|██████████| 15/15 [00:12<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.0502, Val Loss = 0.0405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E3: 100%|██████████| 62/62 [03:42<00:00,  3.59s/it]\n",
      "Val E3: 100%|██████████| 15/15 [00:12<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.0469, Val Loss = 0.0389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E4: 100%|██████████| 62/62 [03:41<00:00,  3.57s/it]\n",
      "Val E4: 100%|██████████| 15/15 [00:12<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.0453, Val Loss = 0.0382\n",
      "\n",
      "Finding optimal thresholds...\n",
      "Label: afraid | Best F1=0.116 @ threshold=0.342\n",
      "Label: angry | Best F1=0.126 @ threshold=0.237\n",
      "Label: anxious | Best F1=0.390 @ threshold=0.348\n",
      "Label: ashamed | Best F1=0.217 @ threshold=0.367\n",
      "Label: awkward | Best F1=0.154 @ threshold=0.432\n",
      "Label: bored | Best F1=0.231 @ threshold=0.278\n",
      "Label: calm | Best F1=0.385 @ threshold=0.352\n",
      "Label: confused | Best F1=0.182 @ threshold=0.266\n",
      "Label: disgusted | Best F1=0.205 @ threshold=0.336\n",
      "Label: excited | Best F1=0.297 @ threshold=0.330\n",
      "Label: frustrated | Best F1=0.576 @ threshold=0.342\n",
      "Label: happy | Best F1=0.660 @ threshold=0.429\n",
      "Label: nostalgic | Best F1=0.137 @ threshold=0.248\n",
      "Label: proud | Best F1=0.378 @ threshold=0.362\n",
      "Label: sad | Best F1=0.286 @ threshold=0.272\n",
      "Label: satisfied | Best F1=0.571 @ threshold=0.428\n",
      "Label: surprised | Best F1=0.147 @ threshold=0.293\n",
      "Label: exercise | Best F1=0.271 @ threshold=0.354\n",
      "Label: family | Best F1=0.364 @ threshold=0.384\n",
      "Label: food | Best F1=0.308 @ threshold=0.391\n",
      "Label: friends | Best F1=0.200 @ threshold=0.319\n",
      "Label: god | Best F1=0.159 @ threshold=0.274\n",
      "Label: health | Best F1=0.196 @ threshold=0.336\n",
      "Label: love | Best F1=0.151 @ threshold=0.279\n",
      "Label: recreation | Best F1=0.134 @ threshold=0.285\n",
      "Label: school | Best F1=0.118 @ threshold=0.324\n",
      "Label: sleep | Best F1=0.354 @ threshold=0.334\n",
      "Label: work | Best F1=0.300 @ threshold=0.353\n",
      "\n",
      "Final Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      afraid       0.00      0.00      0.00         2\n",
      "       angry       0.10      0.40      0.16         5\n",
      "     anxious       0.44      0.74      0.55        23\n",
      "     ashamed       0.00      0.00      0.00         4\n",
      "     awkward       0.00      0.00      0.00         4\n",
      "       bored       0.15      0.13      0.14        15\n",
      "        calm       0.29      1.00      0.46        87\n",
      "    confused       0.33      0.43      0.38         7\n",
      "   disgusted       0.00      0.00      0.00         3\n",
      "     excited       0.16      1.00      0.27        46\n",
      "  frustrated       0.49      0.79      0.60        28\n",
      "       happy       0.52      1.00      0.68       153\n",
      "   nostalgic       0.03      0.67      0.05         6\n",
      "       proud       0.22      1.00      0.37        66\n",
      "         sad       0.18      0.67      0.29         6\n",
      "   satisfied       0.42      1.00      0.59       124\n",
      "   surprised       0.00      0.00      0.00        10\n",
      "    exercise       0.18      0.21      0.19        34\n",
      "      family       0.30      0.91      0.45        53\n",
      "        food       0.58      0.46      0.51        41\n",
      "     friends       0.00      0.00      0.00        20\n",
      "         god       0.35      0.42      0.38        19\n",
      "      health       0.25      0.04      0.07        26\n",
      "        love       0.06      0.20      0.10        10\n",
      "  recreation       0.05      1.00      0.10        16\n",
      "      school       0.00      0.00      0.00         1\n",
      "       sleep       0.10      0.11      0.11        28\n",
      "        work       0.16      1.00      0.27        47\n",
      "\n",
      "   micro avg       0.25      0.77      0.38       884\n",
      "   macro avg       0.19      0.47      0.24       884\n",
      "weighted avg       0.32      0.77      0.42       884\n",
      " samples avg       0.27      0.75      0.38       884\n",
      "\n",
      "Visualizing results...\n",
      "Visualization failed: name 'precision_score' is not defined\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configuration\n",
    "DATA_PATH = \"data.csv\"\n",
    "MODEL_NAME = \"roberta-base\"  # Upgrade to RoBERTa\n",
    "MAX_SEQ_LEN = 256  # Increased sequence length\n",
    "BATCH_SIZE = 16    # Smaller batch size for better gradient estimates\n",
    "LR = 1e-5          # Slightly lower learning rate\n",
    "NUM_EPOCHS = 4     # More epochs\n",
    "WARMUP_RATIO = 0.1\n",
    "N_FOLDS = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "OUTPUT_DIR = \"model_output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# Custom BERT model with attention pooling\n",
    "class EmotionBertModel(nn.Module):\n",
    "    def __init__(self, model_name, num_labels, dropout_rate=0.3):\n",
    "        super(EmotionBertModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        # Attention layer for better sequence representation\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.bert.config.hidden_size, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.bert.config.hidden_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, num_labels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERT embeddings\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
    "        \n",
    "        # Apply attention\n",
    "        attention_weights = self.attention(sequence_output)\n",
    "        context_vector = torch.sum(attention_weights * sequence_output, dim=1)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(context_vector)\n",
    "        return logits\n",
    "\n",
    "# CB-Loss for better handling of imbalanced classes\n",
    "class CBLoss(nn.Module):\n",
    "    def __init__(self, samples_per_class, no_of_classes, beta=0.9999, gamma=2.0):\n",
    "        super(CBLoss, self).__init__()\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.no_of_classes = no_of_classes\n",
    "        \n",
    "        # Calculate effective number of samples\n",
    "        effective_num = 1.0 - np.power(beta, samples_per_class)\n",
    "        weights = (1.0 - beta) / np.array(effective_num)\n",
    "        weights = weights / np.sum(weights) * no_of_classes\n",
    "        self.weights = torch.tensor(weights, dtype=torch.float).to(DEVICE)\n",
    "        \n",
    "    def forward(self, logits, labels):\n",
    "        # BCEWithLogitsLoss with class weights\n",
    "        bce = F.binary_cross_entropy_with_logits(\n",
    "            logits, labels, reduction='none'\n",
    "        )\n",
    "        \n",
    "        # Apply weights\n",
    "        weighted_bce = bce * self.weights\n",
    "        \n",
    "        # Focal component\n",
    "        p = torch.exp(-bce)\n",
    "        focal_weights = (1 - p) ** self.gamma\n",
    "        \n",
    "        # Final loss\n",
    "        loss = (focal_weights * weighted_bce).mean()\n",
    "        return loss\n",
    "\n",
    "# Dataset class\n",
    "class JournalDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.enc = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=MAX_SEQ_LEN,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.enc.input_ids[i],\n",
    "            \"attention_mask\": self.enc.attention_mask[i],\n",
    "            \"labels\": self.labels[i],\n",
    "        }\n",
    "\n",
    "# Optimal threshold finder\n",
    "def find_optimal_thresholds(val_probs, val_labels, label_names):\n",
    "    best_thresholds = {}\n",
    "    \n",
    "    for i, label in enumerate(label_names):\n",
    "        precision, recall, thresholds = precision_recall_curve(val_labels[:, i], val_probs[:, i])\n",
    "        # Adding 0 to thresholds for the case when precision[-1] or recall[-1] is used\n",
    "        thresholds = np.append(thresholds, 1.0)\n",
    "        \n",
    "        # Find threshold that maximizes F1\n",
    "        f1_scores = (2 * precision * recall) / (precision + recall + 1e-10)\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        best_threshold = thresholds[best_idx]\n",
    "        best_f1 = f1_scores[best_idx]\n",
    "        \n",
    "        # Adjust for class frequency\n",
    "        if np.sum(val_labels[:, i]) < 20:  # If very few positive examples\n",
    "            # Make threshold stricter to reduce false positives\n",
    "            best_threshold = min(best_threshold + 0.1, 0.9)\n",
    "        \n",
    "        best_thresholds[label] = best_threshold\n",
    "        print(f\"Label: {label} | Best F1={best_f1:.3f} @ threshold={best_threshold:.3f}\")\n",
    "    \n",
    "    return best_thresholds\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_dl, val_dl, optimizer, scheduler, loss_fn, epochs):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch in tqdm(train_dl, desc=f\"Train E{epoch}\"):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "            labels = batch[\"labels\"].to(DEVICE)\n",
    "            \n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_logits, val_labels_list = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_dl, desc=f\"Val E{epoch}\"):\n",
    "                input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "                attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "                labels = batch[\"labels\"].to(DEVICE)\n",
    "                \n",
    "                logits = model(input_ids, attention_mask)\n",
    "                loss = loss_fn(logits, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_logits.append(logits.cpu())\n",
    "                val_labels_list.append(batch[\"labels\"])\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_dl)\n",
    "        avg_val_loss = val_loss / len(val_dl)\n",
    "        \n",
    "        print(f\"Epoch {epoch}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model\n",
    "\n",
    "# Data augmentation for minority classes\n",
    "def augment_minority_classes(X, y, label_names, min_samples=20):\n",
    "    augmented_X = X.copy()\n",
    "    augmented_y = y.copy()\n",
    "    \n",
    "    for i, label in enumerate(label_names):\n",
    "        # Find indices of positive samples for this label\n",
    "        positive_indices = np.where(y[:, i] == 1)[0]\n",
    "        n_positive = len(positive_indices)\n",
    "        \n",
    "        # If we have too few samples, augment\n",
    "        if n_positive > 0 and n_positive < min_samples:\n",
    "            # Number of duplications needed\n",
    "            n_augment = min(min_samples - n_positive, n_positive * 3)\n",
    "            \n",
    "            # Randomly select samples to duplicate (with replacement)\n",
    "            augment_indices = np.random.choice(positive_indices, size=n_augment, replace=True)\n",
    "            \n",
    "            # Add slight random noise to texts to create variations\n",
    "            new_texts = []\n",
    "            new_labels = []\n",
    "            \n",
    "            for idx in augment_indices:\n",
    "                new_texts.append(augment_text(X[idx]))\n",
    "                new_labels.append(y[idx])\n",
    "            \n",
    "            if new_texts:\n",
    "                augmented_X.extend(new_texts)\n",
    "                augmented_y = np.vstack([augmented_y, np.array(new_labels)])\n",
    "    \n",
    "    print(f\"Original dataset size: {len(X)}, Augmented size: {len(augmented_X)}\")\n",
    "    return augmented_X, augmented_y\n",
    "\n",
    "# Simple text augmentation function\n",
    "def augment_text(text):\n",
    "    words = text.split()\n",
    "    if len(words) <= 5:  # Don't augment very short texts\n",
    "        return text\n",
    "    \n",
    "    # Randomly choose an augmentation strategy\n",
    "    strategy = np.random.choice([\n",
    "        'word_swap',\n",
    "        'word_deletion',\n",
    "        'synonym_replacement'\n",
    "    ])\n",
    "    \n",
    "    if strategy == 'word_swap':\n",
    "        # Swap random adjacent words\n",
    "        if len(words) > 3:\n",
    "            idx = np.random.randint(0, len(words) - 2)\n",
    "            words[idx], words[idx + 1] = words[idx + 1], words[idx]\n",
    "    \n",
    "    elif strategy == 'word_deletion':\n",
    "        # Delete a random word\n",
    "        idx = np.random.randint(0, len(words))\n",
    "        words.pop(idx)\n",
    "    \n",
    "    elif strategy == 'synonym_replacement':\n",
    "        # This is a simplified version (just add a qualifier)\n",
    "        qualifiers = ['really', 'very', 'somewhat', 'quite', 'extremely']\n",
    "        if len(words) > 2:\n",
    "            idx = np.random.randint(0, len(words) - 1)\n",
    "            words.insert(idx, np.random.choice(qualifiers))\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "# Visualization function for results\n",
    "def visualize_results(y_true, y_pred, label_names):\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    support = []\n",
    "    \n",
    "    for i, label in enumerate(label_names):\n",
    "        p = precision_score(y_true[:, i], y_pred[:, i], zero_division=0)\n",
    "        r = recall_score(y_true[:, i], y_pred[:, i], zero_division=0)\n",
    "        f = f1_score(y_true[:, i], y_pred[:, i], zero_division=0)\n",
    "        s = np.sum(y_true[:, i])\n",
    "        \n",
    "        precision.append(p)\n",
    "        recall.append(r)\n",
    "        f1.append(f)\n",
    "        support.append(s)\n",
    "    \n",
    "    # Sort labels by support\n",
    "    indices = np.argsort(support)[::-1]\n",
    "    sorted_labels = [label_names[i] for i in indices]\n",
    "    sorted_precision = [precision[i] for i in indices]\n",
    "    sorted_recall = [recall[i] for i in indices]\n",
    "    sorted_f1 = [f1[i] for i in indices]\n",
    "    sorted_support = [support[i] for i in indices]\n",
    "    \n",
    "    # Plot\n",
    "    x = np.arange(len(sorted_labels))\n",
    "    width = 0.25\n",
    "    \n",
    "    plt.bar(x - width, sorted_precision, width, label='Precision')\n",
    "    plt.bar(x, sorted_recall, width, label='Recall')\n",
    "    plt.bar(x + width, sorted_f1, width, label='F1')\n",
    "    \n",
    "    plt.xlabel('Labels')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Model Performance by Label')\n",
    "    plt.xticks(x, sorted_labels, rotation=90)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add support as text\n",
    "    for i, v in enumerate(sorted_support):\n",
    "        plt.text(i, 0.05, f'n={v}', ha='center')\n",
    "    \n",
    "    plt.savefig(f\"{OUTPUT_DIR}/performance_by_label.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot confusion matrix for each label\n",
    "    for i, label in enumerate(label_names):\n",
    "        cm = confusion_matrix(y_true[:, i], y_pred[:, i])\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=['Negative', 'Positive'],\n",
    "                    yticklabels=['Negative', 'Positive'])\n",
    "        plt.title(f'Confusion Matrix: {label}')\n",
    "        plt.ylabel('True')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{OUTPUT_DIR}/confusion_matrix_{label}.png\")\n",
    "        plt.close()\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    df = clean_create_vectors(df)\n",
    "    \n",
    "    # Identify label columns\n",
    "    y_columns = [c for c in df.columns if c not in [\"journal\", \"emotion_vectors\", \"activity_vectors\", \"text_length\"]]\n",
    "    \n",
    "    # Filter labels: keep only those with at least 5 samples\n",
    "    label_counts = df[y_columns].sum()\n",
    "    unstable_labels = label_counts[label_counts < 5].index.tolist()\n",
    "    if unstable_labels:\n",
    "        print(f\"Removing unstable labels with <5 samples: {unstable_labels}\")\n",
    "    \n",
    "    label_names = [c for c in y_columns if c not in unstable_labels]\n",
    "    num_labels = len(label_names)\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df[\"journal\"].tolist()\n",
    "    y = df[label_names].astype(int).values\n",
    "    \n",
    "    # Get class distribution for loss function\n",
    "    samples_per_class = np.sum(y, axis=0)\n",
    "    print(f\"Class distribution: {dict(zip(label_names, samples_per_class))}\")\n",
    "    \n",
    "    # Train-test split - without stratification to handle rare classes\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Print split statistics\n",
    "    print(f\"Training samples: {len(X_trainval)}, Test samples: {len(X_test)}\")\n",
    "    print(f\"Label distribution in train/test:\")\n",
    "    for i, label in enumerate(label_names):\n",
    "        train_count = np.sum(y_trainval[:, i])\n",
    "        test_count = np.sum(y_test[:, i])\n",
    "        print(f\"  {label}: {train_count} train, {test_count} test\")\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    # Cross-validation setup\n",
    "    try:\n",
    "        mskf = MultilabelStratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "        # Check if stratification is possible\n",
    "        folds = list(mskf.split(X_trainval, y_trainval))\n",
    "        cv_strategy = \"stratified\"\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: MultilabelStratifiedKFold failed ({str(e)}), using regular KFold\")\n",
    "        mskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "        # Create a pseudo-target for stratification based on sum of labels\n",
    "        y_pseudo = np.clip(y_trainval.sum(axis=1), 0, 3)  # 0, 1, 2, 3+ labels\n",
    "        folds = list(mskf.split(X_trainval, y_pseudo))\n",
    "        cv_strategy = \"pseudo-stratified\"\n",
    "    \n",
    "    # Storage for logits and probabilities\n",
    "    all_test_logits = np.zeros((len(X_test), num_labels))\n",
    "    all_val_probs = np.zeros((len(X_trainval), num_labels))\n",
    "    all_val_labels = np.zeros((len(X_trainval), num_labels))\n",
    "    \n",
    "    # Train each fold\n",
    "    for fold, (tr_idx, val_idx) in enumerate(folds, 1):\n",
    "        print(f\"\\n=== Fold {fold}/{N_FOLDS} ({cv_strategy}) ===\")\n",
    "        \n",
    "        # Prepare data with data augmentation for minority classes\n",
    "        X_tr = [X_trainval[i] for i in tr_idx]\n",
    "        y_tr = y_trainval[tr_idx]\n",
    "        X_val = [X_trainval[i] for i in val_idx]\n",
    "        y_val = y_trainval[val_idx]\n",
    "        \n",
    "        # Augment only the training part of this fold\n",
    "        print(\"Augmenting minority classes for this fold...\")\n",
    "        X_tr_aug, y_tr_aug = augment_minority_classes(X_tr, y_tr, label_names)\n",
    "        \n",
    "        # Create datasets and dataloaders\n",
    "        tr_ds = JournalDataset(X_tr_aug, y_tr_aug, tokenizer)\n",
    "        val_ds = JournalDataset(X_val, y_val, tokenizer)\n",
    "        test_ds = JournalDataset(X_test, y_test, tokenizer)\n",
    "        \n",
    "        tr_dl = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "        test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "        \n",
    "        # Initialize model\n",
    "        model = EmotionBertModel(MODEL_NAME, num_labels).to(DEVICE)\n",
    "        \n",
    "        # Initialize optimizer and scheduler\n",
    "        optimizer = AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "        total_steps = len(tr_dl) * NUM_EPOCHS\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=int(total_steps * WARMUP_RATIO),\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "        \n",
    "        # Initialize loss function\n",
    "        loss_fn = CBLoss(samples_per_class, num_labels)\n",
    "        \n",
    "        # Train the model\n",
    "        model = train_model(model, tr_dl, val_dl, optimizer, scheduler, loss_fn, NUM_EPOCHS)\n",
    "        \n",
    "        # Get validation probabilities\n",
    "        model.eval()\n",
    "        val_logits = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dl:\n",
    "                input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "                attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "                logits = model(input_ids, attention_mask).cpu().numpy()\n",
    "                val_logits.append(logits)\n",
    "        \n",
    "        val_logits = np.vstack(val_logits)\n",
    "        val_probs = torch.sigmoid(torch.tensor(val_logits)).numpy()\n",
    "        all_val_probs[val_idx] = val_probs\n",
    "        all_val_labels[val_idx] = y_val\n",
    "        \n",
    "        # Get test logits\n",
    "        test_logits = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_dl:\n",
    "                input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "                attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "                logits = model(input_ids, attention_mask).cpu().numpy()\n",
    "                test_logits.append(logits)\n",
    "        \n",
    "        all_test_logits += np.vstack(test_logits)\n",
    "        \n",
    "        # Save model\n",
    "        torch.save(model.state_dict(), f\"{OUTPUT_DIR}/model_fold{fold}.pt\")\n",
    "    \n",
    "    # Average and convert to probabilities\n",
    "    avg_test_logits = all_test_logits / N_FOLDS\n",
    "    avg_test_probs = torch.sigmoid(torch.tensor(avg_test_logits)).numpy()\n",
    "    \n",
    "    # Find optimal thresholds\n",
    "    print(\"\\nFinding optimal thresholds...\")\n",
    "    best_thresholds = find_optimal_thresholds(all_val_probs, all_val_labels, label_names)\n",
    "    \n",
    "    # Save thresholds\n",
    "    pd.DataFrame(list(best_thresholds.items()), columns=['label', 'threshold']).to_csv(\n",
    "        f\"{OUTPUT_DIR}/thresholds.csv\", index=False\n",
    "    )\n",
    "    \n",
    "    # Apply thresholds to get predictions\n",
    "    final_preds = np.zeros_like(avg_test_probs, dtype=int)\n",
    "    for i, label in enumerate(label_names):\n",
    "        t = best_thresholds[label]\n",
    "        final_preds[:, i] = (avg_test_probs[:, i] >= t).astype(int)\n",
    "    \n",
    "    # Evaluate and visualize results\n",
    "    print(\"\\nFinal Classification Report:\")\n",
    "    report = classification_report(\n",
    "        y_test, final_preds,\n",
    "        target_names=label_names,\n",
    "        zero_division=0\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    # Save classification report\n",
    "    with open(f\"{OUTPUT_DIR}/classification_report.txt\", \"w\") as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    # Visualize results\n",
    "    try:\n",
    "        from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "        print(\"Visualizing results...\")\n",
    "        visualize_results(y_test, final_preds, label_names)\n",
    "    except Exception as e:\n",
    "        print(f\"Visualization failed: {e}\")\n",
    "    \n",
    "    print(\"Done!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "from transformers import AutoTokenizer, TFRobertaModel, TFDebertaModel\n",
    "\n",
    "# <-- import your cleaning functions -->\n",
    "from data_cleaning_import import clean_create_vectors  # or create_student_vectors\n",
    "\n",
    "# -------------------------\n",
    "# Metrics & helpers\n",
    "# -------------------------\n",
    "def f1_score(true, pred):\n",
    "    true, pred = np.array(true), np.array(pred)\n",
    "    tp = np.sum((true == 1) & (pred == 1))\n",
    "    pp = np.sum(pred == 1)\n",
    "    ta = np.sum(true == 1)\n",
    "    if pp==0 or ta==0: return 0.0\n",
    "    prec = tp/pp; rec = tp/ta\n",
    "    return 2*prec*rec/(prec+rec) if (prec+rec)>0 else 0.0\n",
    "\n",
    "def precision_score(true, pred):\n",
    "    true, pred = np.array(true), np.array(pred)\n",
    "    tp = np.sum((true == 1) & (pred == 1))\n",
    "    pp = np.sum(pred == 1)\n",
    "    return tp/pp if pp>0 else 0.0\n",
    "\n",
    "def recall_score(true, pred):\n",
    "    true, pred = np.array(true), np.array(pred)\n",
    "    tp = np.sum((true == 1) & (pred == 1))\n",
    "    ta = np.sum(true == 1)\n",
    "    return tp/ta if ta>0 else 0.0\n",
    "\n",
    "def normalized_accuracy(true, pred):\n",
    "    true, pred = np.array(true), np.array(pred)\n",
    "    tp = np.sum((true == 1) & (pred == 1))\n",
    "    tn = np.sum((true == 0) & (pred == 0))\n",
    "    ta = np.sum(true == 1); tn_all = np.sum(true == 0)\n",
    "    if ta==0 or tn_all==0: return 0.0\n",
    "    return (tp/ta + tn/tn_all)/2\n",
    "\n",
    "def calculate_class_weights(labels):\n",
    "    counts = np.sum(labels, axis=0)\n",
    "    total = labels.shape[0]\n",
    "    weights = {}\n",
    "    for i,c in enumerate(counts):\n",
    "        weights[i] = total/(len(counts)*c) if c>0 else 1.0\n",
    "    return weights\n",
    "\n",
    "# -------------------------\n",
    "# Classifier\n",
    "# -------------------------\n",
    "class JournalEmotionClassifier:\n",
    "    def __init__(self, model_name=\"roberta-base\", max_length=128,\n",
    "                 num_classes=29, class_weights=None, output_dir=\"./output\"):\n",
    "        self.model_name   = model_name\n",
    "        self.max_length   = max_length\n",
    "        self.num_classes  = num_classes\n",
    "        self.class_weights= class_weights\n",
    "        self.output_dir   = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.class_names = [\n",
    "            'afraid','angry','anxious','ashamed','awkward','bored','calm',\n",
    "            'confused','disgusted','excited','frustrated','happy','jealous',\n",
    "            'nostalgic','proud','sad','satisfied','surprised',\n",
    "            'exercise','family','food','friends','god','health','love',\n",
    "            'recreation','school','sleep','work'\n",
    "        ]\n",
    "        self.thresholds = {c:0.5 for c in self.class_names}\n",
    "\n",
    "    def build_model(self):\n",
    "        if \"deberta\" in self.model_name:\n",
    "            base = TFDebertaModel.from_pretrained(self.model_name)\n",
    "        else:\n",
    "            base = TFRobertaModel.from_pretrained(self.model_name)\n",
    "\n",
    "        ids = Input(shape=(self.max_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "        mask= Input(shape=(self.max_length,), dtype=tf.int32, name=\"attention_mask\")\n",
    "        out = base(input_ids=ids, attention_mask=mask)[0][:,0,:]\n",
    "        x   = Dropout(0.1)(out)\n",
    "        x   = Dense(512, activation=\"relu\")(x)\n",
    "        x   = Dropout(0.2)(x)\n",
    "        logits = Dense(self.num_classes, activation=\"sigmoid\")(x)\n",
    "\n",
    "        self.model = Model([ids,mask], logits)\n",
    "        self.model.compile(\n",
    "            optimizer=Adam(2e-5),\n",
    "            loss=BinaryCrossentropy(),\n",
    "            metrics=['accuracy', AUC(multi_label=True, name='auc')]\n",
    "        )\n",
    "        return self.model\n",
    "\n",
    "    def preprocess(self, texts):\n",
    "        return self.tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "\n",
    "    def train(self, df, label_cols, val_split=0.2, batch_size=16, epochs=10):\n",
    "        texts = df['journal'].tolist()\n",
    "        labels= df[label_cols].values\n",
    "\n",
    "        if val_split>0:\n",
    "            tX,vX,tY,vY = train_test_split(\n",
    "                texts, labels, test_size=val_split, random_state=42\n",
    "            )\n",
    "            ti = self.preprocess(tX); vi = self.preprocess(vX)\n",
    "            callbacks = [\n",
    "                EarlyStopping(\"val_auc\", patience=3, mode=\"max\", restore_best_weights=True),\n",
    "                ModelCheckpoint(os.path.join(self.output_dir,\"best_model.h5\"),\n",
    "                                monitor=\"val_auc\", mode=\"max\", save_best_only=True)\n",
    "            ]\n",
    "            h = self.model.fit(\n",
    "                ti, tY,\n",
    "                validation_data=(vi,vY),\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                callbacks=callbacks,\n",
    "                class_weight=self.class_weights\n",
    "            )\n",
    "            pd.DataFrame(h.history).to_csv(\n",
    "                os.path.join(self.output_dir, \"training_history.csv\"), index=False\n",
    "            )\n",
    "        else:\n",
    "            inp = self.preprocess(texts)\n",
    "            h   = self.model.fit(\n",
    "                inp, labels,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                class_weight=self.class_weights\n",
    "            )\n",
    "            self.model.save_weights(os.path.join(self.output_dir,\"final_model.h5\"))\n",
    "\n",
    "    def optimize_thresholds(self, df, label_cols, metric='f1_score'):\n",
    "        texts = df['journal'].tolist()\n",
    "        labels= df[label_cols].values\n",
    "        inp   = self.preprocess(texts)\n",
    "        raw   = self.model.predict(inp)\n",
    "        bests = {}\n",
    "        for idx,name in enumerate(self.class_names):\n",
    "            best_score, best_t = 0,0.5\n",
    "            for t in np.arange(0.1,1.0,0.05):\n",
    "                binp = (raw[:,idx]>=t).astype(int)\n",
    "                if metric=='precision':\n",
    "                    sc = precision_score(labels[:,idx],binp)\n",
    "                elif metric=='recall':\n",
    "                    sc = recall_score(labels[:,idx],binp)\n",
    "                elif metric=='norm_acc':\n",
    "                    sc = normalized_accuracy(labels[:,idx],binp)\n",
    "                else:\n",
    "                    sc = f1_score(labels[:,idx],binp)\n",
    "                if sc>best_score:\n",
    "                    best_score, best_t = sc,t\n",
    "            bests[name]=best_t\n",
    "        self.thresholds = bests\n",
    "        pd.DataFrame([bests]).to_csv(\n",
    "            os.path.join(self.output_dir,\"optimal_thresholds.csv\"),\n",
    "            index=False\n",
    "        )\n",
    "        return bests\n",
    "\n",
    "    def evaluate(self, df, label_cols):\n",
    "        texts = df['journal'].tolist()\n",
    "        labels= df[label_cols].values\n",
    "        inp   = self.preprocess(texts)\n",
    "        raw   = self.model.predict(inp)\n",
    "\n",
    "        binp  = np.zeros_like(raw)\n",
    "        for idx,name in enumerate(self.class_names):\n",
    "            binp[:,idx] = raw[:,idx] >= self.thresholds[name]\n",
    "\n",
    "        results = {}\n",
    "        for fn in (f1_score, precision_score, recall_score, normalized_accuracy):\n",
    "            scores = []\n",
    "            for i in range(len(self.class_names)):\n",
    "                sc = fn(labels[:,i], binp[:,i])\n",
    "                results[f\"{fn.__name__}_{self.class_names[i]}\"] = sc\n",
    "                scores.append(sc)\n",
    "            results[f\"{fn.__name__}_macro_avg\"] = np.mean(scores)\n",
    "\n",
    "        pd.DataFrame([results]).to_csv(\n",
    "            os.path.join(self.output_dir,\"evaluation_results.csv\"), index=False\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def save(self, path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        self.model.save_weights(os.path.join(path,\"model_weights.h5\"))\n",
    "        self.tokenizer.save_pretrained(path)\n",
    "        np.save(os.path.join(path,\"thresholds.npy\"), self.thresholds)\n",
    "\n",
    "    def predict(self, texts):\n",
    "        inp   = self.preprocess(texts)\n",
    "        raw   = self.model.predict(inp)\n",
    "        binp  = np.zeros_like(raw)\n",
    "        for idx,name in enumerate(self.class_names):\n",
    "            binp[:,idx] = raw[:,idx] >= self.thresholds[name]\n",
    "        return raw, binp\n",
    "\n",
    "# -------------------------\n",
    "# Main\n",
    "# -------------------------\n",
    "def main():\n",
    "    # 1. read raw CSV & clean\n",
    "    raw_df = pd.read_csv(\"data.csv\")\n",
    "    df     = clean_create_vectors(raw_df)\n",
    "\n",
    "    # 2. define labels\n",
    "    label_cols = [\n",
    "        'afraid','angry','anxious','ashamed','awkward','bored','calm',\n",
    "        'confused','disgusted','excited','frustrated','happy','jealous',\n",
    "        'nostalgic','proud','sad','satisfied','surprised',\n",
    "        'exercise','family','food','friends','god','health','love',\n",
    "        'recreation','school','sleep','work'\n",
    "    ]\n",
    "\n",
    "    # 3. train/test split\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    print(f\"Train size: {len(train_df)}  Test size: {len(test_df)}\")\n",
    "\n",
    "    # 4. class weights\n",
    "    cw = calculate_class_weights(train_df[label_cols].values)\n",
    "\n",
    "    # 5. init & build model\n",
    "    clf = JournalEmotionClassifier(\n",
    "        model_name=\"roberta-base\",\n",
    "        max_length=128,\n",
    "        num_classes=len(label_cols),\n",
    "        class_weights=cw,\n",
    "        output_dir=\"./journal_output\"\n",
    "    )\n",
    "    clf.build_model()\n",
    "\n",
    "    # 6. train\n",
    "    print(\"Training…\")\n",
    "    clf.train(train_df, label_cols, val_split=0.1, batch_size=16, epochs=5)\n",
    "\n",
    "    # 7. optimize thresholds\n",
    "    print(\"Optimizing thresholds…\")\n",
    "    best_t = clf.optimize_thresholds(test_df, label_cols)\n",
    "    print(best_t)\n",
    "\n",
    "    # 8. evaluate\n",
    "    print(\"Evaluating…\")\n",
    "    metrics = clf.evaluate(test_df, label_cols)\n",
    "    for k,v in metrics.items():\n",
    "        if k.endswith(\"_macro_avg\"):\n",
    "            print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    # 9. save final model\n",
    "    clf.save(\"./journal_output/final_model\")\n",
    "\n",
    "    # 10. example predictions\n",
    "    samples = [\n",
    "        \"I spent the evening with friends and felt really happy.\",\n",
    "        \"Work was stressful and I couldn't sleep at all.\",\n",
    "        \"I had a calm walk in the park and felt nostalgic.\"\n",
    "    ]\n",
    "    raw_preds, bin_preds = clf.predict(samples)\n",
    "    print(\"\\nExample predictions:\")\n",
    "    for i, txt in enumerate(samples):\n",
    "        print(f\"\\n- {txt}\")\n",
    "        for idx in np.where(bin_preds[i]==1)[0]:\n",
    "            print(f\"   • {clf.class_names[idx]} ({raw_preds[i,idx]:.2f})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
